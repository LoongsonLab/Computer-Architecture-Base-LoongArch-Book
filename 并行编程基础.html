<!DOCTYPE html>
<html lang="zh-CN" xml:lang="zh-CN">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第 10 章 并行编程基础 | 计算机体系结构基础</title>
  <meta name="description" content="第 10 章 并行编程基础 | 计算机体系结构基础" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="第 10 章 并行编程基础 | 计算机体系结构基础" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="第 10 章 并行编程基础 | 计算机体系结构基础" />
  <meta name="github-repo" content="foxsen/archbase" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第 10 章 并行编程基础 | 计算机体系结构基础" />
  
  <meta name="twitter:description" content="第 10 章 并行编程基础 | 计算机体系结构基础" />
  

<meta name="author" content="胡伟武 汪文祥 苏孟豪 张福新 王焕东 章隆兵 肖俊华 刘 苏 陈新科 吴瑞阳 李晓钰 高燕萍" />


<meta name="date" content="2023-08-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="指令流水线.html"/>
<link rel="next" href="多核处理结构.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<link href="libs/tabwid/tabwid.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">计算机体系结构基础</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>丛书序言</a></li>
<li class="chapter" data-level="" data-path="推荐序.html"><a href="推荐序.html"><i class="fa fa-check"></i>推荐序</a></li>
<li class="chapter" data-level="" data-path="自序.html"><a href="自序.html"><i class="fa fa-check"></i>自序</a></li>
<li class="chapter" data-level="" data-path="第三版序.html"><a href="第三版序.html"><i class="fa fa-check"></i>第三版序</a></li>
<li class="chapter" data-level="" data-path="前言.html"><a href="前言.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="关于本书的在线版本.html"><a href="关于本书的在线版本.html"><i class="fa fa-check"></i>关于本书的在线版本</a></li>
<li class="part"><span><b>I 引言</b></span></li>
<li class="chapter" data-level="1" data-path="引言.html"><a href="引言.html"><i class="fa fa-check"></i><b>1</b> 引言</a>
<ul>
<li class="chapter" data-level="1.1" data-path="引言.html"><a href="引言.html#计算机体系结构的研究内容"><i class="fa fa-check"></i><b>1.1</b> 计算机体系结构的研究内容</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="引言.html"><a href="引言.html#一以贯之"><i class="fa fa-check"></i><b>1.1.1</b> 一以贯之</a></li>
<li class="chapter" data-level="1.1.2" data-path="引言.html"><a href="引言.html#什么是计算机"><i class="fa fa-check"></i><b>1.1.2</b> 什么是计算机</a></li>
<li class="chapter" data-level="1.1.3" data-path="引言.html"><a href="引言.html#计算机的基本组成"><i class="fa fa-check"></i><b>1.1.3</b> 计算机的基本组成</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="引言.html"><a href="引言.html#衡量计算机的指标"><i class="fa fa-check"></i><b>1.2</b> 衡量计算机的指标</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="引言.html"><a href="引言.html#计算机的性能"><i class="fa fa-check"></i><b>1.2.1</b> 计算机的性能</a></li>
<li class="chapter" data-level="1.2.2" data-path="引言.html"><a href="引言.html#计算机的价格"><i class="fa fa-check"></i><b>1.2.2</b> 计算机的价格</a></li>
<li class="chapter" data-level="1.2.3" data-path="引言.html"><a href="引言.html#计算机的功耗"><i class="fa fa-check"></i><b>1.2.3</b> 计算机的功耗</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="引言.html"><a href="引言.html#计算机体系结构的发展"><i class="fa fa-check"></i><b>1.3</b> 计算机体系结构的发展</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="引言.html"><a href="引言.html#摩尔定律和工艺的发展"><i class="fa fa-check"></i><b>1.3.1</b> 摩尔定律和工艺的发展</a></li>
<li class="chapter" data-level="1.3.2" data-path="引言.html"><a href="引言.html#计算机应用和体系结构"><i class="fa fa-check"></i><b>1.3.2</b> 计算机应用和体系结构</a></li>
<li class="chapter" data-level="1.3.3" data-path="引言.html"><a href="引言.html#计算机体系结构发展"><i class="fa fa-check"></i><b>1.3.3</b> 计算机体系结构发展</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="引言.html"><a href="引言.html#体系结构设计的基本原则"><i class="fa fa-check"></i><b>1.4</b> 体系结构设计的基本原则</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="引言.html"><a href="引言.html#平衡性"><i class="fa fa-check"></i><b>1.4.1</b> 平衡性</a></li>
<li class="chapter" data-level="1.4.2" data-path="引言.html"><a href="引言.html#局部性"><i class="fa fa-check"></i><b>1.4.2</b> 局部性</a></li>
<li class="chapter" data-level="1.4.3" data-path="引言.html"><a href="引言.html#并行性"><i class="fa fa-check"></i><b>1.4.3</b> 并行性</a></li>
<li class="chapter" data-level="1.4.4" data-path="引言.html"><a href="引言.html#虚拟化"><i class="fa fa-check"></i><b>1.4.4</b> 虚拟化</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="引言.html"><a href="引言.html#本章小结"><i class="fa fa-check"></i><b>1.5</b> 本章小结</a></li>
<li class="chapter" data-level="1.6" data-path="引言.html"><a href="引言.html#习题"><i class="fa fa-check"></i><b>1.6</b> 习题</a></li>
</ul></li>
<li class="part"><span><b>II 指令系统结构</b></span></li>
<li class="chapter" data-level="2" data-path="sec-ISA.html"><a href="sec-ISA.html"><i class="fa fa-check"></i><b>2</b> 指令系统</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec-ISA.html"><a href="sec-ISA.html#指令系统简介"><i class="fa fa-check"></i><b>2.1</b> 指令系统简介</a></li>
<li class="chapter" data-level="2.2" data-path="sec-ISA.html"><a href="sec-ISA.html#指令系统设计原则"><i class="fa fa-check"></i><b>2.2</b> 指令系统设计原则</a></li>
<li class="chapter" data-level="2.3" data-path="sec-ISA.html"><a href="sec-ISA.html#指令系统发展历程"><i class="fa fa-check"></i><b>2.3</b> 指令系统发展历程</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="sec-ISA.html"><a href="sec-ISA.html#指令内容的演变"><i class="fa fa-check"></i><b>2.3.1</b> 指令内容的演变</a></li>
<li class="chapter" data-level="2.3.2" data-path="sec-ISA.html"><a href="sec-ISA.html#存储管理的演变"><i class="fa fa-check"></i><b>2.3.2</b> 存储管理的演变</a></li>
<li class="chapter" data-level="2.3.3" data-path="sec-ISA.html"><a href="sec-ISA.html#运行级别的演变"><i class="fa fa-check"></i><b>2.3.3</b> 运行级别的演变</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="sec-ISA.html"><a href="sec-ISA.html#指令系统组成"><i class="fa fa-check"></i><b>2.4</b> 指令系统组成</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="sec-ISA.html"><a href="sec-ISA.html#地址空间"><i class="fa fa-check"></i><b>2.4.1</b> 地址空间</a></li>
<li class="chapter" data-level="2.4.2" data-path="sec-ISA.html"><a href="sec-ISA.html#操作数"><i class="fa fa-check"></i><b>2.4.2</b> 操作数</a></li>
<li class="chapter" data-level="2.4.3" data-path="sec-ISA.html"><a href="sec-ISA.html#指令操作和编码"><i class="fa fa-check"></i><b>2.4.3</b> 指令操作和编码</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="sec-ISA.html"><a href="sec-ISA.html#risc指令集比较"><i class="fa fa-check"></i><b>2.5</b> RISC指令集比较</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="sec-ISA.html"><a href="sec-ISA.html#指令格式比较"><i class="fa fa-check"></i><b>2.5.1</b> 指令格式比较</a></li>
<li class="chapter" data-level="2.5.2" data-path="sec-ISA.html"><a href="sec-ISA.html#寻址方式比较"><i class="fa fa-check"></i><b>2.5.2</b> 寻址方式比较</a></li>
<li class="chapter" data-level="2.5.3" data-path="sec-ISA.html"><a href="sec-ISA.html#公共指令功能"><i class="fa fa-check"></i><b>2.5.3</b> 公共指令功能</a></li>
<li class="chapter" data-level="2.5.4" data-path="sec-ISA.html"><a href="sec-ISA.html#不同指令系统的特色"><i class="fa fa-check"></i><b>2.5.4</b> 不同指令系统的特色</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="sec-ISA.html"><a href="sec-ISA.html#c语言的机器表示"><i class="fa fa-check"></i><b>2.6</b> C语言的机器表示</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="sec-ISA.html"><a href="sec-ISA.html#过程调用"><i class="fa fa-check"></i><b>2.6.1</b> 过程调用</a></li>
<li class="chapter" data-level="2.6.2" data-path="sec-ISA.html"><a href="sec-ISA.html#流程控制语句"><i class="fa fa-check"></i><b>2.6.2</b> 流程控制语句</a></li>
<li class="chapter" data-level="2.6.3" data-path="sec-ISA.html"><a href="sec-ISA.html#循环语句"><i class="fa fa-check"></i><b>2.6.3</b> 循环语句</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="sec-ISA.html"><a href="sec-ISA.html#本章小结-1"><i class="fa fa-check"></i><b>2.7</b> 本章小结</a></li>
<li class="chapter" data-level="2.8" data-path="sec-ISA.html"><a href="sec-ISA.html#习题-1"><i class="fa fa-check"></i><b>2.8</b> 习题</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sec-privileged-ISA.html"><a href="sec-privileged-ISA.html"><i class="fa fa-check"></i><b>3</b> 特权指令系统</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec-privileged-ISA.html"><a href="sec-privileged-ISA.html#特权指令系统简介"><i class="fa fa-check"></i><b>3.1</b> 特权指令系统简介</a></li>
<li class="chapter" data-level="3.2" data-path="sec-privileged-ISA.html"><a href="sec-privileged-ISA.html#sec-exception"><i class="fa fa-check"></i><b>3.2</b> 异常与中断</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sec-privileged-ISA.html"><a href="sec-privileged-ISA.html#异常分类"><i class="fa fa-check"></i><b>3.2.1</b> 异常分类</a></li>
<li class="chapter" data-level="3.2.2" data-path="sec-privileged-ISA.html"><a href="sec-privileged-ISA.html#异常处理"><i class="fa fa-check"></i><b>3.2.2</b> 异常处理</a></li>
<li class="chapter" data-level="3.2.3" data-path="sec-privileged-ISA.html"><a href="sec-privileged-ISA.html#中断"><i class="fa fa-check"></i><b>3.2.3</b> 中断</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec-privileged-ISA.html"><a href="sec-privileged-ISA.html#sec-memory-management"><i class="fa fa-check"></i><b>3.3</b> 存储管理</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="sec-privileged-ISA.html"><a href="sec-privileged-ISA.html#存储管理的原理"><i class="fa fa-check"></i><b>3.3.1</b> 存储管理的原理</a></li>
<li class="chapter" data-level="3.3.2" data-path="sec-privileged-ISA.html"><a href="sec-privileged-ISA.html#tlb的结构和使用"><i class="fa fa-check"></i><b>3.3.2</b> TLB的结构和使用</a></li>
<li class="chapter" data-level="3.3.3" data-path="sec-privileged-ISA.html"><a href="sec-privileged-ISA.html#sec-tlb-ex"><i class="fa fa-check"></i><b>3.3.3</b> TLB地址翻译相关异常的处理</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sec-privileged-ISA.html"><a href="sec-privileged-ISA.html#本章小结-2"><i class="fa fa-check"></i><b>3.4</b> 本章小结</a></li>
<li class="chapter" data-level="3.5" data-path="sec-privileged-ISA.html"><a href="sec-privileged-ISA.html#习题-2"><i class="fa fa-check"></i><b>3.5</b> 习题</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="软硬件协同.html"><a href="软硬件协同.html"><i class="fa fa-check"></i><b>4</b> 软硬件协同</a>
<ul>
<li class="chapter" data-level="4.1" data-path="软硬件协同.html"><a href="软硬件协同.html#应用程序二进制接口"><i class="fa fa-check"></i><b>4.1</b> 应用程序二进制接口</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="软硬件协同.html"><a href="软硬件协同.html#寄存器约定"><i class="fa fa-check"></i><b>4.1.1</b> 寄存器约定</a></li>
<li class="chapter" data-level="4.1.2" data-path="软硬件协同.html"><a href="软硬件协同.html#函数调用约定"><i class="fa fa-check"></i><b>4.1.2</b> 函数调用约定</a></li>
<li class="chapter" data-level="4.1.3" data-path="软硬件协同.html"><a href="软硬件协同.html#进程虚拟地址空间"><i class="fa fa-check"></i><b>4.1.3</b> 进程虚拟地址空间</a></li>
<li class="chapter" data-level="4.1.4" data-path="软硬件协同.html"><a href="软硬件协同.html#栈帧布局"><i class="fa fa-check"></i><b>4.1.4</b> 栈帧布局</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="软硬件协同.html"><a href="软硬件协同.html#六种常见的上下文切换场景"><i class="fa fa-check"></i><b>4.2</b> 六种常见的上下文切换场景</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="软硬件协同.html"><a href="软硬件协同.html#函数调用"><i class="fa fa-check"></i><b>4.2.1</b> 函数调用</a></li>
<li class="chapter" data-level="4.2.2" data-path="软硬件协同.html"><a href="软硬件协同.html#异常和中断"><i class="fa fa-check"></i><b>4.2.2</b> 异常和中断</a></li>
<li class="chapter" data-level="4.2.3" data-path="软硬件协同.html"><a href="软硬件协同.html#系统调用"><i class="fa fa-check"></i><b>4.2.3</b> 系统调用</a></li>
<li class="chapter" data-level="4.2.4" data-path="软硬件协同.html"><a href="软硬件协同.html#进程"><i class="fa fa-check"></i><b>4.2.4</b> 进程</a></li>
<li class="chapter" data-level="4.2.5" data-path="软硬件协同.html"><a href="软硬件协同.html#线程"><i class="fa fa-check"></i><b>4.2.5</b> 线程</a></li>
<li class="chapter" data-level="4.2.6" data-path="软硬件协同.html"><a href="软硬件协同.html#虚拟机"><i class="fa fa-check"></i><b>4.2.6</b> 虚拟机</a></li>
<li class="chapter" data-level="4.2.7" data-path="软硬件协同.html"><a href="软硬件协同.html#六种上下文切换场景的对比"><i class="fa fa-check"></i><b>4.2.7</b> 六种上下文切换场景的对比</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="软硬件协同.html"><a href="软硬件协同.html#同步机制"><i class="fa fa-check"></i><b>4.3</b> 同步机制</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="软硬件协同.html"><a href="软硬件协同.html#基于互斥的同步机制"><i class="fa fa-check"></i><b>4.3.1</b> 基于互斥的同步机制</a></li>
<li class="chapter" data-level="4.3.2" data-path="软硬件协同.html"><a href="软硬件协同.html#非阻塞的同步机制"><i class="fa fa-check"></i><b>4.3.2</b> 非阻塞的同步机制</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="软硬件协同.html"><a href="软硬件协同.html#本章小结-3"><i class="fa fa-check"></i><b>4.4</b> 本章小结</a></li>
<li class="chapter" data-level="4.5" data-path="软硬件协同.html"><a href="软硬件协同.html#习题-3"><i class="fa fa-check"></i><b>4.5</b> 习题</a></li>
</ul></li>
<li class="part"><span><b>III 计算机硬件结构</b></span></li>
<li class="chapter" data-level="5" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html"><i class="fa fa-check"></i><b>5</b> 计算机组成原理和结构</a>
<ul>
<li class="chapter" data-level="5.1" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#冯诺依曼结构"><i class="fa fa-check"></i><b>5.1</b> 冯·诺依曼结构</a></li>
<li class="chapter" data-level="5.2" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#计算机的组成部件"><i class="fa fa-check"></i><b>5.2</b> 计算机的组成部件</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#运算器"><i class="fa fa-check"></i><b>5.2.1</b> 运算器</a></li>
<li class="chapter" data-level="5.2.2" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#控制器"><i class="fa fa-check"></i><b>5.2.2</b> 控制器</a></li>
<li class="chapter" data-level="5.2.3" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#存储器"><i class="fa fa-check"></i><b>5.2.3</b> 存储器</a></li>
<li class="chapter" data-level="5.2.4" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#输入输出设备"><i class="fa fa-check"></i><b>5.2.4</b> 输入/输出设备</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#计算机系统硬件结构发展"><i class="fa fa-check"></i><b>5.3</b> 计算机系统硬件结构发展</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#cpu-gpu-北桥-南桥四片结构"><i class="fa fa-check"></i><b>5.3.1</b> CPU-GPU-北桥-南桥四片结构</a></li>
<li class="chapter" data-level="5.3.2" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#cpu-北桥-南桥三片结构"><i class="fa fa-check"></i><b>5.3.2</b> CPU-北桥-南桥三片结构</a></li>
<li class="chapter" data-level="5.3.3" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#cpu-弱北桥-南桥三片结构"><i class="fa fa-check"></i><b>5.3.3</b> CPU-弱北桥-南桥三片结构</a></li>
<li class="chapter" data-level="5.3.4" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#cpu-南桥两片结构"><i class="fa fa-check"></i><b>5.3.4</b> CPU-南桥两片结构</a></li>
<li class="chapter" data-level="5.3.5" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#soc单片结构"><i class="fa fa-check"></i><b>5.3.5</b> SoC单片结构</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#处理器和io设备间的通信"><i class="fa fa-check"></i><b>5.4</b> 处理器和IO设备间的通信</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#io寄存器寻址"><i class="fa fa-check"></i><b>5.4.1</b> IO寄存器寻址</a></li>
<li class="chapter" data-level="5.4.2" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#处理器和io设备之间的同步"><i class="fa fa-check"></i><b>5.4.2</b> 处理器和IO设备之间的同步</a></li>
<li class="chapter" data-level="5.4.3" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#存储器和io设备之间的数据传送"><i class="fa fa-check"></i><b>5.4.3</b> 存储器和IO设备之间的数据传送</a></li>
<li class="chapter" data-level="5.4.4" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#龙芯3a30007a1000桥片系统中的cpugpudc通信"><i class="fa fa-check"></i><b>5.4.4</b> 龙芯3A3000+7A1000桥片系统中的CPU、GPU、DC通信</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#本章小结-4"><i class="fa fa-check"></i><b>5.5</b> 本章小结</a></li>
<li class="chapter" data-level="5.6" data-path="计算机组成原理和结构.html"><a href="计算机组成原理和结构.html#习题-4"><i class="fa fa-check"></i><b>5.6</b> 习题</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html"><i class="fa fa-check"></i><b>6</b> 计算机总线接口技术</a>
<ul>
<li class="chapter" data-level="6.1" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html#总线概述"><i class="fa fa-check"></i><b>6.1</b> 总线概述</a></li>
<li class="chapter" data-level="6.2" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html#总线分类"><i class="fa fa-check"></i><b>6.2</b> 总线分类</a></li>
<li class="chapter" data-level="6.3" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html#片上总线"><i class="fa fa-check"></i><b>6.3</b> 片上总线</a></li>
<li class="chapter" data-level="6.4" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html#内存总线"><i class="fa fa-check"></i><b>6.4</b> 内存总线</a></li>
<li class="chapter" data-level="6.5" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html#系统总线"><i class="fa fa-check"></i><b>6.5</b> 系统总线</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html#hypertransport总线"><i class="fa fa-check"></i><b>6.5.1</b> HyperTransport总线</a></li>
<li class="chapter" data-level="6.5.2" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html#ht包格式"><i class="fa fa-check"></i><b>6.5.2</b> HT包格式</a></li>
<li class="chapter" data-level="6.5.3" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html#设备总线"><i class="fa fa-check"></i><b>6.5.3</b> 设备总线</a></li>
<li class="chapter" data-level="6.5.4" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html#pcie总线"><i class="fa fa-check"></i><b>6.5.4</b> PCIE总线</a></li>
<li class="chapter" data-level="6.5.5" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html#pcie包格式"><i class="fa fa-check"></i><b>6.5.5</b> PCIE包格式</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html#本章小结-5"><i class="fa fa-check"></i><b>6.6</b> 本章小结</a></li>
<li class="chapter" data-level="6.7" data-path="计算机总线接口技术.html"><a href="计算机总线接口技术.html#习题-5"><i class="fa fa-check"></i><b>6.7</b> 习题</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html"><i class="fa fa-check"></i><b>7</b> 计算机启动过程分析</a>
<ul>
<li class="chapter" data-level="7.1" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#处理器核初始化"><i class="fa fa-check"></i><b>7.1</b> 处理器核初始化</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#sec-cpu-reset"><i class="fa fa-check"></i><b>7.1.1</b> 处理器复位</a></li>
<li class="chapter" data-level="7.1.2" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#调试接口初始化"><i class="fa fa-check"></i><b>7.1.2</b> 调试接口初始化</a></li>
<li class="chapter" data-level="7.1.3" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#tlb初始化"><i class="fa fa-check"></i><b>7.1.3</b> TLB初始化</a></li>
<li class="chapter" data-level="7.1.4" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#cache初始化"><i class="fa fa-check"></i><b>7.1.4</b> Cache初始化</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#总线接口初始化"><i class="fa fa-check"></i><b>7.2</b> 总线接口初始化</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#内存初始化"><i class="fa fa-check"></i><b>7.2.1</b> 内存初始化</a></li>
<li class="chapter" data-level="7.2.2" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#io总线初始化"><i class="fa fa-check"></i><b>7.2.2</b> IO总线初始化</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#设备的探测及驱动加载"><i class="fa fa-check"></i><b>7.3</b> 设备的探测及驱动加载</a></li>
<li class="chapter" data-level="7.4" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#多核启动过程"><i class="fa fa-check"></i><b>7.4</b> 多核启动过程</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#初始化时的多核协同"><i class="fa fa-check"></i><b>7.4.1</b> 初始化时的多核协同</a></li>
<li class="chapter" data-level="7.4.2" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#操作系统启动时的多核唤醒"><i class="fa fa-check"></i><b>7.4.2</b> 操作系统启动时的多核唤醒</a></li>
<li class="chapter" data-level="7.4.3" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#核间同步与通信"><i class="fa fa-check"></i><b>7.4.3</b> 核间同步与通信</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#本章小结-6"><i class="fa fa-check"></i><b>7.5</b> 本章小结</a></li>
<li class="chapter" data-level="7.6" data-path="计算机启动过程分析.html"><a href="计算机启动过程分析.html#习题-6"><i class="fa fa-check"></i><b>7.6</b> 习题</a></li>
</ul></li>
<li class="part"><span><b>IV CPU的微结构</b></span></li>
<li class="chapter" data-level="8" data-path="运算器设计.html"><a href="运算器设计.html"><i class="fa fa-check"></i><b>8</b> 运算器设计</a>
<ul>
<li class="chapter" data-level="8.1" data-path="运算器设计.html"><a href="运算器设计.html#二进制与逻辑电路"><i class="fa fa-check"></i><b>8.1</b> 二进制与逻辑电路</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="运算器设计.html"><a href="运算器设计.html#sec-number-presentation"><i class="fa fa-check"></i><b>8.1.1</b> 计算机中数的表示</a></li>
<li class="chapter" data-level="8.1.2" data-path="运算器设计.html"><a href="运算器设计.html#sec-MOS-principle"><i class="fa fa-check"></i><b>8.1.2</b> MOS晶体管工作原理</a></li>
<li class="chapter" data-level="8.1.3" data-path="运算器设计.html"><a href="运算器设计.html#cmos逻辑电路"><i class="fa fa-check"></i><b>8.1.3</b> CMOS逻辑电路</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="运算器设计.html"><a href="运算器设计.html#简单运算器设计"><i class="fa fa-check"></i><b>8.2</b> 简单运算器设计</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="运算器设计.html"><a href="运算器设计.html#定点补码加法器"><i class="fa fa-check"></i><b>8.2.1</b> 定点补码加法器</a></li>
<li class="chapter" data-level="8.2.2" data-path="运算器设计.html"><a href="运算器设计.html#减法运算实现"><i class="fa fa-check"></i><b>8.2.2</b> 减法运算实现</a></li>
<li class="chapter" data-level="8.2.3" data-path="运算器设计.html"><a href="运算器设计.html#比较运算实现"><i class="fa fa-check"></i><b>8.2.3</b> 比较运算实现</a></li>
<li class="chapter" data-level="8.2.4" data-path="运算器设计.html"><a href="运算器设计.html#移位器"><i class="fa fa-check"></i><b>8.2.4</b> 移位器</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="运算器设计.html"><a href="运算器设计.html#定点补码乘法器"><i class="fa fa-check"></i><b>8.3</b> 定点补码乘法器</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="运算器设计.html"><a href="运算器设计.html#补码乘法器"><i class="fa fa-check"></i><b>8.3.1</b> 补码乘法器</a></li>
<li class="chapter" data-level="8.3.2" data-path="运算器设计.html"><a href="运算器设计.html#booth乘法器"><i class="fa fa-check"></i><b>8.3.2</b> Booth乘法器</a></li>
<li class="chapter" data-level="8.3.3" data-path="运算器设计.html"><a href="运算器设计.html#华莱士树"><i class="fa fa-check"></i><b>8.3.3</b> 华莱士树</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="运算器设计.html"><a href="运算器设计.html#本章小结-7"><i class="fa fa-check"></i><b>8.4</b> 本章小结</a></li>
<li class="chapter" data-level="8.5" data-path="运算器设计.html"><a href="运算器设计.html#习题-7"><i class="fa fa-check"></i><b>8.5</b> 习题</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="指令流水线.html"><a href="指令流水线.html"><i class="fa fa-check"></i><b>9</b> 指令流水线</a>
<ul>
<li class="chapter" data-level="9.1" data-path="指令流水线.html"><a href="指令流水线.html#单周期处理器"><i class="fa fa-check"></i><b>9.1</b> 单周期处理器</a></li>
<li class="chapter" data-level="9.2" data-path="指令流水线.html"><a href="指令流水线.html#sec-pipeline-cpu"><i class="fa fa-check"></i><b>9.2</b> 流水线处理器</a></li>
<li class="chapter" data-level="9.3" data-path="指令流水线.html"><a href="指令流水线.html#sec-hazard"><i class="fa fa-check"></i><b>9.3</b> 指令相关和流水线冲突</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="指令流水线.html"><a href="指令流水线.html#数据相关引发的冲突及解决办法"><i class="fa fa-check"></i><b>9.3.1</b> 数据相关引发的冲突及解决办法</a></li>
<li class="chapter" data-level="9.3.2" data-path="指令流水线.html"><a href="指令流水线.html#sec-control-hazard"><i class="fa fa-check"></i><b>9.3.2</b> 控制相关引发冲突及解决方法</a></li>
<li class="chapter" data-level="9.3.3" data-path="指令流水线.html"><a href="指令流水线.html#结构相关引发冲突及解决办法"><i class="fa fa-check"></i><b>9.3.3</b> 结构相关引发冲突及解决办法</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="指令流水线.html"><a href="指令流水线.html#sec-precise-exception"><i class="fa fa-check"></i><b>9.4</b> 流水线与异常处理</a></li>
<li class="chapter" data-level="9.5" data-path="指令流水线.html"><a href="指令流水线.html#提高流水线效率的技术"><i class="fa fa-check"></i><b>9.5</b> 提高流水线效率的技术</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="指令流水线.html"><a href="指令流水线.html#多发射数据通路"><i class="fa fa-check"></i><b>9.5.1</b> 多发射数据通路</a></li>
<li class="chapter" data-level="9.5.2" data-path="指令流水线.html"><a href="指令流水线.html#sec-dynamic"><i class="fa fa-check"></i><b>9.5.2</b> 动态调度</a></li>
<li class="chapter" data-level="9.5.3" data-path="指令流水线.html"><a href="指令流水线.html#sec-branch-predict"><i class="fa fa-check"></i><b>9.5.3</b> 转移预测</a></li>
<li class="chapter" data-level="9.5.4" data-path="指令流水线.html"><a href="指令流水线.html#高速缓存"><i class="fa fa-check"></i><b>9.5.4</b> 高速缓存</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="指令流水线.html"><a href="指令流水线.html#本章小结-8"><i class="fa fa-check"></i><b>9.6</b> 本章小结</a></li>
<li class="chapter" data-level="9.7" data-path="指令流水线.html"><a href="指令流水线.html#习题-8"><i class="fa fa-check"></i><b>9.7</b> 习题</a></li>
</ul></li>
<li class="part"><span><b>V 并行处理结构</b></span></li>
<li class="chapter" data-level="10" data-path="并行编程基础.html"><a href="并行编程基础.html"><i class="fa fa-check"></i><b>10</b> 并行编程基础</a>
<ul>
<li class="chapter" data-level="10.1" data-path="并行编程基础.html"><a href="并行编程基础.html#程序的并行行为"><i class="fa fa-check"></i><b>10.1</b> 程序的并行行为</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="并行编程基础.html"><a href="并行编程基础.html#指令级并行性"><i class="fa fa-check"></i><b>10.1.1</b> 指令级并行性</a></li>
<li class="chapter" data-level="10.1.2" data-path="并行编程基础.html"><a href="并行编程基础.html#数据级并行性"><i class="fa fa-check"></i><b>10.1.2</b> 数据级并行性</a></li>
<li class="chapter" data-level="10.1.3" data-path="并行编程基础.html"><a href="并行编程基础.html#任务级并行性"><i class="fa fa-check"></i><b>10.1.3</b> 任务级并行性</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="并行编程基础.html"><a href="并行编程基础.html#并行编程模型"><i class="fa fa-check"></i><b>10.2</b> 并行编程模型</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="并行编程基础.html"><a href="并行编程基础.html#单任务数据并行模型"><i class="fa fa-check"></i><b>10.2.1</b> 单任务数据并行模型</a></li>
<li class="chapter" data-level="10.2.2" data-path="并行编程基础.html"><a href="并行编程基础.html#多任务共享存储编程模型"><i class="fa fa-check"></i><b>10.2.2</b> 多任务共享存储编程模型</a></li>
<li class="chapter" data-level="10.2.3" data-path="并行编程基础.html"><a href="并行编程基础.html#多任务消息传递编程模型"><i class="fa fa-check"></i><b>10.2.3</b> 多任务消息传递编程模型</a></li>
<li class="chapter" data-level="10.2.4" data-path="并行编程基础.html"><a href="并行编程基础.html#共享存储与消息传递编程模型的编程复杂度"><i class="fa fa-check"></i><b>10.2.4</b> 共享存储与消息传递编程模型的编程复杂度</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="并行编程基础.html"><a href="并行编程基础.html#典型并行编程环境"><i class="fa fa-check"></i><b>10.3</b> 典型并行编程环境</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="并行编程基础.html"><a href="并行编程基础.html#数据并行simd编程"><i class="fa fa-check"></i><b>10.3.1</b> 数据并行SIMD编程</a></li>
<li class="chapter" data-level="10.3.2" data-path="并行编程基础.html"><a href="并行编程基础.html#posix编程标准"><i class="fa fa-check"></i><b>10.3.2</b> POSIX编程标准</a></li>
<li class="chapter" data-level="10.3.3" data-path="并行编程基础.html"><a href="并行编程基础.html#openmp标准"><i class="fa fa-check"></i><b>10.3.3</b> OpenMP标准</a></li>
<li class="chapter" data-level="10.3.4" data-path="并行编程基础.html"><a href="并行编程基础.html#消息传递编程接口"><i class="fa fa-check"></i><b>10.3.4</b> 消息传递编程接口</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="并行编程基础.html"><a href="并行编程基础.html#习题-9"><i class="fa fa-check"></i><b>10.4</b> 习题</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="多核处理结构.html"><a href="多核处理结构.html"><i class="fa fa-check"></i><b>11</b> 多核处理结构</a>
<ul>
<li class="chapter" data-level="11.1" data-path="多核处理结构.html"><a href="多核处理结构.html#多核处理器的发展演化"><i class="fa fa-check"></i><b>11.1</b> 多核处理器的发展演化</a></li>
<li class="chapter" data-level="11.2" data-path="多核处理结构.html"><a href="多核处理结构.html#多核处理器的访存结构"><i class="fa fa-check"></i><b>11.2</b> 多核处理器的访存结构</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="多核处理结构.html"><a href="多核处理结构.html#通用多核处理器的片上cache结构"><i class="fa fa-check"></i><b>11.2.1</b> 通用多核处理器的片上Cache结构</a></li>
<li class="chapter" data-level="11.2.2" data-path="多核处理结构.html"><a href="多核处理结构.html#存储一致性模型"><i class="fa fa-check"></i><b>11.2.2</b> 存储一致性模型</a></li>
<li class="chapter" data-level="11.2.3" data-path="多核处理结构.html"><a href="多核处理结构.html#cache一致性协议"><i class="fa fa-check"></i><b>11.2.3</b> Cache一致性协议</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="多核处理结构.html"><a href="多核处理结构.html#多核处理器的互连结构"><i class="fa fa-check"></i><b>11.3</b> 多核处理器的互连结构</a></li>
<li class="chapter" data-level="11.4" data-path="多核处理结构.html"><a href="多核处理结构.html#多核处理器的同步机制"><i class="fa fa-check"></i><b>11.4</b> 多核处理器的同步机制</a></li>
<li class="chapter" data-level="11.5" data-path="多核处理结构.html"><a href="多核处理结构.html#典型多核处理器"><i class="fa fa-check"></i><b>11.5</b> 典型多核处理器</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="多核处理结构.html"><a href="多核处理结构.html#龙芯3a5000处理器"><i class="fa fa-check"></i><b>11.5.1</b> 龙芯3A5000处理器</a></li>
<li class="chapter" data-level="11.5.2" data-path="多核处理结构.html"><a href="多核处理结构.html#intel-sandybridge架构"><i class="fa fa-check"></i><b>11.5.2</b> Intel SandyBridge架构</a></li>
<li class="chapter" data-level="11.5.3" data-path="多核处理结构.html"><a href="多核处理结构.html#ibm-cell处理器"><i class="fa fa-check"></i><b>11.5.3</b> IBM Cell处理器</a></li>
<li class="chapter" data-level="11.5.4" data-path="多核处理结构.html"><a href="多核处理结构.html#nvidia-gpu"><i class="fa fa-check"></i><b>11.5.4</b> NVIDIA GPU</a></li>
<li class="chapter" data-level="11.5.5" data-path="多核处理结构.html"><a href="多核处理结构.html#tile64处理器"><i class="fa fa-check"></i><b>11.5.5</b> Tile64处理器</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="多核处理结构.html"><a href="多核处理结构.html#本章小结-9"><i class="fa fa-check"></i><b>11.6</b> 本章小结</a></li>
<li class="chapter" data-level="11.7" data-path="多核处理结构.html"><a href="多核处理结构.html#习题-10"><i class="fa fa-check"></i><b>11.7</b> 习题</a></li>
</ul></li>
<li class="part"><span><b>VI 系统性能评价与分析</b></span></li>
<li class="chapter" data-level="12" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html"><i class="fa fa-check"></i><b>12</b> 计算机系统性能评价与性能分析</a>
<ul>
<li class="chapter" data-level="12.1" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#计算机系统性能评价指标"><i class="fa fa-check"></i><b>12.1</b> 计算机系统性能评价指标</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#计算机系统常用性能评价指标"><i class="fa fa-check"></i><b>12.1.1</b> 计算机系统常用性能评价指标</a></li>
<li class="chapter" data-level="12.1.2" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#并行系统的性能评价指标"><i class="fa fa-check"></i><b>12.1.2</b> 并行系统的性能评价指标</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#测试程序集"><i class="fa fa-check"></i><b>12.2</b> 测试程序集</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#微基准测试程序"><i class="fa fa-check"></i><b>12.2.1</b> 微基准测试程序</a></li>
<li class="chapter" data-level="12.2.2" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#spec-cpu基准测试程序"><i class="fa fa-check"></i><b>12.2.2</b> SPEC CPU基准测试程序</a></li>
<li class="chapter" data-level="12.2.3" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#并行系统基准测试程序"><i class="fa fa-check"></i><b>12.2.3</b> 并行系统基准测试程序</a></li>
<li class="chapter" data-level="12.2.4" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#其他常见的基准测试程序集"><i class="fa fa-check"></i><b>12.2.4</b> 其他常见的基准测试程序集</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#性能分析方法"><i class="fa fa-check"></i><b>12.3</b> 性能分析方法</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#分析建模的方法"><i class="fa fa-check"></i><b>12.3.1</b> 分析建模的方法</a></li>
<li class="chapter" data-level="12.3.2" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#模拟建模的方法和模拟器"><i class="fa fa-check"></i><b>12.3.2</b> 模拟建模的方法和模拟器</a></li>
<li class="chapter" data-level="12.3.3" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#性能测量的方法"><i class="fa fa-check"></i><b>12.3.3</b> 性能测量的方法</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#性能测试和分析实例"><i class="fa fa-check"></i><b>12.4</b> 性能测试和分析实例</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#spec-cpu基准测试程序的分值对比"><i class="fa fa-check"></i><b>12.4.1</b> SPEC CPU基准测试程序的分值对比</a></li>
<li class="chapter" data-level="12.4.2" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#微结构相关统计数据"><i class="fa fa-check"></i><b>12.4.2</b> 微结构相关统计数据</a></li>
<li class="chapter" data-level="12.4.3" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#基础性能参数"><i class="fa fa-check"></i><b>12.4.3</b> 基础性能参数</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#本章小结-10"><i class="fa fa-check"></i><b>12.5</b> 本章小结</a></li>
<li class="chapter" data-level="12.6" data-path="计算机系统性能评价与性能分析.html"><a href="计算机系统性能评价与性能分析.html#习题-11"><i class="fa fa-check"></i><b>12.6</b> 习题</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="总结.html"><a href="总结.html"><i class="fa fa-check"></i>总结</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>参考文献</a></li>
<li class="chapter" data-level="" data-path="相关资源.html"><a href="相关资源.html"><i class="fa fa-check"></i>相关资源</a>
<ul>
<li class="chapter" data-level="" data-path="相关资源.html"><a href="相关资源.html#自动生成的各种格式"><i class="fa fa-check"></i>自动生成的各种格式</a></li>
<li class="chapter" data-level="" data-path="相关资源.html"><a href="相关资源.html#其他"><i class="fa fa-check"></i>其他</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="http://www.loongson.cn" target="blank">本书电子版由龙芯中科赞助提供</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">计算机体系结构基础</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="并行编程基础" class="section level1" number="10">
<h1><span class="header-section-number">第 10 章</span> 并行编程基础</h1>
<div id="程序的并行行为" class="section level2" number="10.1">
<h2><span class="header-section-number">10.1</span> 程序的并行行为</h2>
<p>人们对应用程序性能的追求是无止境的，例如天气预报、药物设计、核武器模拟等应用。并行处理系统可以协同多个处理单元来解决同一个问题，从而大幅度提升性能。评价一个并行处理系统，主要看其执行程序的性能（即程序在其上的执行时间）。可以通过一些公认的并行测试程序集（如SPLASH、NAS）来进行评测。因此，在讨论并行处理结构之前，先来看一下程序的并行行为。程序的并行行为主要包括指令级并行性、数据级并行、任务级并行性。</p>
<div id="指令级并行性" class="section level3" number="10.1.1">
<h3><span class="header-section-number">10.1.1</span> 指令级并行性</h3>
<p>指令级并行性（Instruction Level Parallelism，简称ILP）主要指指令之间的并行性，当指令之间不存在相关时，这些指令可以在处理器流水线上重叠起来并行执行。在程序运行中，如果必须等前一条指令执行完成后，才能执行后一条指令，那么这两条指令是相关的。指令相关主要包括数据相关、控制相关和结构相关。数据相关包括写后读（Read After Write，简称RAW）相关、读后写（Write AfterRead，简称WAR）相关和写后写（WriteAfter Write，简称WAW）相关。其中RAW相关是真正的数据相关，因为存在真正的数据传递关系；WAR相关和WAW相关又称为假相关或者名字相关，指令之间实际不存在数据传递。控制相关主要是由于存在分支指令，一条指令的执行取决于该分支指令的执行结果，则这两条指令之间存在控制相关。结构相关是指两条指令同时需要流水线中的同一个功能部件。在这些相关中，RAW数据相关和控制相关是真正制约指令级并行执行的相关。指令相关容易造成处理器流水线上的冲突，引起流水线阻塞，从而降低流水线效率。</p>
<p>现代处理器采用多种微结构设计技术挖掘指令级并行性，包括指令流水线、多发射、动态调度、寄存器重命名、转移猜测等技术。指令流水线重叠执行多条不相关的指令；多发射技术允许一个时钟周期执行多条指令，类似于“多车道”；动态调度允许后续指令越过前面被阻塞的指令继续被调度执行，相当于允许“超车”；寄存器重命名主要解决WAR和WAW的假相关问题；转移猜测技术可以猜测分支指令的方向和目标，在分支指令还未执行完之前获取更多可执行指令，以减少控制相关造成的指令流水线阻塞。这方面的技术已经比较成熟。</p>
</div>
<div id="数据级并行性" class="section level3" number="10.1.2">
<h3><span class="header-section-number">10.1.2</span> 数据级并行性</h3>
<p>数据级并行性（Data Level Parallelism，简称DLP）是指对集合或者数组中的元素同时执行相同的操作。这种并行性通常来源于程序中的循环语句。下列代码块所示的代码就是一个数据并行的例子。对于数组local中的元素local[i],执行相同的操作(i+0.5)*w。可以采用将不同的数据分布到不同的处理单元的方式来实现数据级并行。</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb30-1"><a href="并行编程基础.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i=<span class="dv">0</span>;i&lt;N;i++) {</span>
<span id="cb30-2"><a href="并行编程基础.html#cb30-2" aria-hidden="true" tabindex="-1"></a>    local[i] = (i+<span class="fl">0.5</span>)*w;</span>
<span id="cb30-3"><a href="并行编程基础.html#cb30-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>数据级并行性是比较易于处理的，可以在计算机体系结构的多个层次来利用数据级并行性。例如：可以在处理器中设计向量功能部件，采用SIMD设计方法，如一个256位向量部件一次可以执行4个64位的操作；设计专门的向量处理器，如CRAY公司的CRAY-1、CRAY-2、X-MP、Y-MP等；在多处理器中，可以采用SPMD（Single Program Multi-Data）的编程方式，将数据分布到不同的处理器上执行同一个程序控制流。数据级并行性常见于科学和工程计算领域中，例如大规模线性方程组的求解等。正是由于这个原因，向量处理器在科学计算领域还是比较成功的。</p>
</div>
<div id="任务级并行性" class="section level3" number="10.1.3">
<h3><span class="header-section-number">10.1.3</span> 任务级并行性</h3>
<p>任务级并行性（Task Level Parallelism）是将不同的任务（进程或者线程）分布到不同的处理单元上执行。针对任务表现为进程或者线程，任务级并行性可分为进程级并行性或者线程级并行性。下代码块是一个任务并行的代码示例。对于一个双处理器系统，当处理器ID（processor_ID）为a时，则执行任务A；当处理器ID为b时则执行任务B。</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb31-1"><a href="并行编程基础.html#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(processor_ID=”a”) {</span>
<span id="cb31-2"><a href="并行编程基础.html#cb31-2" aria-hidden="true" tabindex="-1"></a>    task A;</span>
<span id="cb31-3"><a href="并行编程基础.html#cb31-3" aria-hidden="true" tabindex="-1"></a>}<span class="cf">else</span> <span class="cf">if</span> (processor_ID=”b”){</span>
<span id="cb31-4"><a href="并行编程基础.html#cb31-4" aria-hidden="true" tabindex="-1"></a>    Task B;</span>
<span id="cb31-5"><a href="并行编程基础.html#cb31-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>在并行处理系统中，挖掘任务并行性就是让每个处理器执行不同的线程或进程来处理相同或者不同的数据。这些线程或者进程可以执行相同或者不同的代码。通常情况下，不同线程或者进程之间还需要相互通信来协作完成整个程序的执行。任务级并行性常见于商业应用领域，如大规模数据库的事务处理等。另外，多道程序工作负载（Multiprogramming Workload），即在计算机系统上运行多道独立的程序，也是任务级并行的重要来源。</p>
</div>
</div>
<div id="并行编程模型" class="section level2" number="10.2">
<h2><span class="header-section-number">10.2</span> 并行编程模型</h2>
<p>并行处理系统上如何编程是个难题，目前并没有很好地解决。并行编程模型的目标是方便编程人员开发出能在并行处理系统上高效运行的并行程序。并行编程模型（Parallel Programming Model）是一种程序抽象的集合，它给程序员提供了一幅计算机硬件/软件系统的抽象简图，程序员利用这些模型就可以为多核处理器、多处理器、机群等并行计算系统设计并行程序[26]。</p>
<div id="单任务数据并行模型" class="section level3" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> 单任务数据并行模型</h3>
<p>数据并行（Data Parallel）模型是指对集合或者数组中的元素同时（即并行）执行相同操作。数据并行编程模型可以在SIMD计算机上实现，为单任务数据并行；也可以在SPMD计算机上实现，为多任务数据并行。SIMD着重开发指令级细粒度的并行性，SPMD着重开发子程序级中粒度的并行性。单任务数据并行编程模型具有以下特点：</p>
<p>1)单线程（Single Threading）。从程序员的角度，一个数据并行程序只由一个线程执行，具有单一控制线；就控制流而言，一个数据并行程序就像一个顺序程序一样。</p>
<p>2）同构并行。数据并行程序的一条语句，同时作用在不同数组元素或者其他聚合数据结构，在数据并行程序的每条语句之后，均有一个隐式同步。</p>
<p>3）全局命名空间（Global Naming Space）。数据并行程序中的所有变量均在单一地址空间内，所有语句可访问任何变量而只要满足通常的变量作用域规则即可。</p>
<p>4）隐式相互作用（Implicit Interaction）。因为数据并行程序的每条语句结束时存在一个隐含的栅障（Barrier），所以不需要显式同步；通信可以由变量指派而隐含地完成。</p>
<p>5）隐式数据分配（Implicit Data Allocation）。程序员没必要明确指定如何分配数据，可将改进数据局部性和减少通信的数据分配方法提示给编译器。</p>
</div>
<div id="多任务共享存储编程模型" class="section level3" number="10.2.2">
<h3><span class="header-section-number">10.2.2</span> 多任务共享存储编程模型</h3>
<p>在共享存储编程模型中，运行在各处理器上的进程（或者线程）可以通过读/写共享存储器中的共享变量来相互通信。它与单任务数据并行模型的相似之处在于有一个单一的全局名字空间。由于数据是在一个单一的共享地址空间中，因此不需要显式地分配数据，而工作负载则可以显式地分配也可以隐式地分配。通信通过共享的读/写变量隐式地完成，而同步必须显式地完成，以保持进程执行的正确顺序。共享存储编程模型如Pthreads和OpenMP等。</p>
</div>
<div id="多任务消息传递编程模型" class="section level3" number="10.2.3">
<h3><span class="header-section-number">10.2.3</span> 多任务消息传递编程模型</h3>
<p>在消息传递编程模型中，在不同处理器节点上运行的进程，可以通过网络传递消息而相互通信。在消息传递并行程序中，用户必须明确为进程分配数据和负载，它比较适合开发大粒度的并行性，这些程序是多进程的和异步的，要求显式同步（如栅障等）以确保正确的执行顺序。然而这些进程均有独立的地址空间。</p>
<p>消息传递编程模型具有以下特点：</p>
<p>1）多进程。消息传递并行程序由多个进程组成，每个进程都有自己的控制流且可执行不同代码；多程序多数据（Multiple ProgramMultiple Data，简称MPMD）并行和单程序多数据（SPMD）并行均可支持。</p>
<p>2）异步并行性（Asynchronous Parallelism）。消息传递并行程序的各进程彼此异步执行，使用诸如栅障和阻塞通信等方式来同步各个进程。</p>
<p>3）独立的地址空间（Separate Address Space）。消息传递并行程序的进程具有各自独立的地址空间，一个进程的数据变量对其他进程是不可见的，进程的相互作用通过执行特殊的消息传递操作来实现。</p>
<p>4）显式相互作用（Explicit Interaction）。程序员必须解决包括数据映射、通信、同步和聚合等相互作用问题；计算任务分配通过拥有者-计算（Owner-Compute）规则来完成，即进程只能在其拥有的数据上进行计算。</p>
<p>5）显式分配（Explicit Allocation）。计算任务和数据均由用户显式地分配给进程，为了减少设计和编程的复杂性，用户通常采用单一代码方法来编写SPMD程序。典型的消息传递编程模型包括MPI和PVM。</p>
</div>
<div id="共享存储与消息传递编程模型的编程复杂度" class="section level3" number="10.2.4">
<h3><span class="header-section-number">10.2.4</span> 共享存储与消息传递编程模型的编程复杂度</h3>
<p>采用共享存储与消息传递编程模型编写的并行程序是在多处理器并行处理系统上运行的。先了解一下多处理器的结构特点，可以更好地理解并行编程模型。从结构的角度看，多处理器系统可分为共享存储系统和消息传递系统两类。在共享存储系统中，所有处理器共享主存储器，每个处理器都可以把信息存入主存储器，或从中取出信息，处理器之间的通信通过访问共享存储器来实现。而在消息传递系统中，每个处理器都有一个只有它自己才能访问的局部存储器，处理器之间的通信必须通过显式的消息传递来进行。消息传递和共享存储系统的原理结构如图<a href="并行编程基础.html#fig:programming">10.1</a>所示。从图中可以看出，在消息传递系统中，每个处理器的存储器是单独编址的；而在共享存储系统中，所有存储器统一编址。典型的共享存储多处理器结构包括对称多处理器机（Symmetric Multi-Processor，简称SMP）结构、高速缓存一致非均匀存储器访问（Cache Coherent Non Uniform Memory Access，简称CC-NUMA）结构。</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:programming"></span>
<img src="images/chapter10/Shared_storage_and_message_passing_programming.png" alt="消息传递（左）和共享存储系统（右）" width="100%" />
<p class="caption">
图 10.1: 消息传递（左）和共享存储系统（右）
</p>
</div>
<p>在消息传递编程模型中，程序员需要对计算任务和数据进行划分，并安排并行程序执行过程中进程间的所有通信。在共享存储编程模型中，由于程序的多进程（或者线程）之间存在一个统一编址的共享存储空间，程序员只需进行计算任务划分，不必进行数据划分，也不用确切地知道并行程序执行过程中进程间的通信。MPP（Massive Parallel Processing）系统和机群系统往往是消息传递系统。消息传递系统的可伸缩性通常比共享存储系统要好，可支持更多处理器。</p>
<p>从进程（或者线程）间通信的角度看，消息传递并行10.6程序比共享存储并行程序复杂一些，体现在时间管理和空间管理两方面。在空间管理方面，发送数据的进程需要关心自己产生的数据被谁用到，而接收数据的进程需要关心它用到了谁产生的数据；在时间管理方面，发送数据的进程通常需要在数据被接收后才能继续，而接收数据的进程通常需要等到接收数据后才能继续。在共享存储并行程序中，各进程间的通信通过访问共享存储器完成，程序员只需考虑进程间同步，不用考虑进程间通信。尤其是比较复杂的数据结构的通信，如struct{int<em>pa;int</em> pb;int*pc;}，消息传递并行程序比共享存储并行程序复杂得多。此外，对于一些在编程时难以确切知道进程间通信的程序，用消息传递的方法很难进行并行化，如{for (i,j){ x=…; y=…; a[i][j]=b[x][y];}}。这段代码中，通信特征在程序运行时才能确定，编写代码时难以确定，改写成消息传递程序就比较困难。</p>
<p>从数据划分的角度看，消息传递并行程序必须考虑诸如数组名称以及下标变换等因素，在将一个串行程序改写成并行程序的过程中，需要修改大量的程序代码。而在共享存储编程模型中进行串行程序的并行化改写时，不用进行数组名称以及下标变换，对代码的修改量少。虽说共享存储程序无须考虑数据划分，但是在实际应用中，为了获得更高的系统性能，有时也需要考虑数据分布，使得数据尽量分布在对其进行计算的处理器上，例如OpenMP中就有进行数据分布的扩展指导。不过，相对于消息传递程序中的数据划分考虑数据分布还是要简单得多。</p>
<p>总的来说，共享存储编程像BBS应用，一个人向BBS上发帖子，其他人都看得见；消息传递编程则像电子邮件(E-mail)，你得想好给谁发邮件，发什么内容。</p>
<p>下面举两个共享存储和消息传递程序的例子。第一个例子是通过积分求圆周率。积分求圆周率的公式如下：
<span class="math display">\[
\pi = 4\int_{0}^{1}{\frac{1}{1+x^2}}dx = \sum^{N}_{i=1}{\frac{4}{1+(\frac{i-0.5}{N})^2}\times{\frac{1}{N}}}
\]</span></p>
<p>在上式中，N值越大，误差越小。如果N值很大，计算时间就很长。可以通过并行处理，让每个进程计算其中的一部分，最后把每个进程计算的值加在一起来减少运算时间。图<a href="并行编程基础.html#fig:get-pi">10.2</a>给出了计算圆周率的共享存储（基于中科院计算所开发的JIAJIA虚拟共享存储系统）和消息传递并行程序核心片段的算法示意。该并行程序采用SPMD（Single Program Multiple Data）的模式，即每个进程都运行同一个程序，但处理不同的数据。在该程序中，numprocs是参与运算的进程个数，所有参与运算的进程都有相同的numprocs值；myid是参与运算的进程的编号，每个进程都有自己的编号（一般并行编程系统都会提供接口函数让进程知道自己的编号）。例如，如果有4个进程参与运算，则每个进程的numprocs都是4，而每个进程的myid号分别为0、1、2、3。在共享存储并行程序中，由jia_alloc()分配空间的变量pi是所有参与运算的进程共享的，所有进程只有一份，其他变量都是每个进程局部的，每个进程都有一份，每个进程根据numprocs和myid号分别计算部分的圆周率值，最后通过一个临界区的机制把所有进程的计算结果加在一起。jia_lock()和jia_unlock()是一种临界区的锁机制，保证每次只有一个进程进入这个临界区，这样才能把所有进程的结果依次加在一起，不会互相冲掉。在消息传递并行程序中，由malloc()分配空间的变量每个进程都有独立的一份，互相看不见。每个进程算完部分结果后，通过归约操作reduce()把所有进程的mypi加到0号进程的pi中。</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:get-pi"></span>
<img src="images/chapter10/%E7%A7%AF%E5%88%86%E6%B1%82%E5%9C%86%E5%91%A8%E7%8E%87%E7%AE%97%E6%B3%95%E7%A4%BA%E6%84%8F-01.png" alt="积分求圆周率算法示意" width="100%" />
<p class="caption">
图 10.2: 积分求圆周率算法示意
</p>
</div>
<p>第二个例子是矩阵乘法。矩阵乘法的算法大家都很熟悉，这里就不介绍了。图<a href="并行编程基础.html#fig:get-martix-multi">10.3</a>给出了共享存储和消息传递并行程序。同样，由jia_alloc()分配的变量所有进程共享一份，而由malloc()分配的变量每个进程单独一份，因此在这个程序中消息传递并行程序需要更多的内存。在共享存储并行程序中，先由0号进程对A、B、C三个矩阵进行初始化，而其他进程通过jia_barrier()语句等待。barrier是并行程序中常用的同步方式，它要求所有进程都等齐后再前进。然后每个进程分别完成部分运算，再通过jia_barrier()等齐后由0号进程统一打印结果。消息传递并行程序与共享存储并行程序的最大区别是需要通过显式的发送语句send和接收语句recv进行多个进程之间的通信。先由0号进程进行初始化后发送给其他进程，每个进程分别算完后再发送给0号进程进行打印。在消息传递并行程序中要详细列出每次发送的数据大小和起始地址等信息，0号进程接收的时候还要把从其他进程收到的数据拼接在一个矩阵中，比共享存储并行程序麻烦不少。</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:get-martix-multi"></span>
<img src="images/chapter10/%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E7%AE%97%E6%B3%95%E7%A4%BA%E6%84%8F-01.png" alt="矩阵乘法算法示意" width="100%" />
<p class="caption">
图 10.3: 矩阵乘法算法示意
</p>
</div>
</div>
</div>
<div id="典型并行编程环境" class="section level2" number="10.3">
<h2><span class="header-section-number">10.3</span> 典型并行编程环境</h2>
<p>本节主要介绍数据并行SIMD编程、早期的共享存储编程标准Pthreads、目前主流的共享存储编程标准OpenMP和消息传递编程模型（MPI）等。</p>
<div id="数据并行simd编程" class="section level3" number="10.3.1">
<h3><span class="header-section-number">10.3.1</span> 数据并行SIMD编程</h3>
<p>工业界广泛应用的单指令流多数据流(Single Instruction Multiple Data，简称SIMD)并行就是典型的数据并行技术。相比于传统的标量处理器上的单指令流单数据流(Single Instruction Single Data，简称SISD)指令，一条SIMD指令可以同时对一组数据进行相同的计算。比如将两个数组SRC0[8]和SRC1[8]中的每个对应元素求和，将结果放入数组RESULT中，对于传统的标量处理器平台，C语言实现如下：</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb32-1"><a href="并行编程基础.html#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; <span class="dv">8</span>; i++)</span>
<span id="cb32-2"><a href="并行编程基础.html#cb32-2" aria-hidden="true" tabindex="-1"></a>        RESULT[i] = SRC0[i] + SRC1[i];</span></code></pre></div>
<p>也就是通过循环遍历需要求和的8组对应数据，对SRC0和SRC1的各对应项求和，将结果存入RESULT数组的对应项中。在龙芯处理器平台上，用机器指令(汇编代码)实现该运算的代码如下(这里假设$src0、 $src1、 $result分别为存储了SRC0、 SRC1和RESULT数组起始地址的通用寄存器)：</p>
<pre class="assembly"><code>li  $4, 0x0
li  $5, 0x8
1:  daddu   $src0, $4
    daddu   $src1, $4
    daddu$result, $4
lb  $6, 0x0($src0)
    lb  $7, 0x0($src1)
    daddu   $6, $6, $7
    sb  $6, 0x0($result)
    daddiu  $4, 0x1
    blt $4, $5, 1b
    nop</code></pre>
<p>如果采用龙芯处理器的SIMD指令编写程序的话，上述两个数组的求和只需要将上述两个源操作数数组SRC0[8]和SRC1[8]一次性加载到龙芯处理器的向量寄存器(龙芯向量寄存器复用了浮点寄存器)中，然后只需要一条paddb指令就可以完成上述8个对应数组项的求和，最后只需要一条store指令就可以将结果存回RESULT[8]数组所在的内存空间中。该实现的机器指令序列如下：</p>
<pre class="assembly"><code>    gsldxc1 $f0, 0x0($src0, $0)
    gsldxc1 $f2, 0x0($src1, $0)
    paddb   $f0, $f0, $f2
    gssdxc1 $f0, 0x0($result, $0)</code></pre>
<p>​ 图<a href="并行编程基础.html#fig:SISD-SIMD">10.4</a>简要示意了采用传统SISD指令和SIMD指令实现上述8个对应数组项求和的执行控制流程。</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:SISD-SIMD"></span>
<img src="images/chapter10/SISD_SIMD.png" alt="SISD和SIMD执行控制流示意图" width="100%" />
<p class="caption">
图 10.4: SISD和SIMD执行控制流示意图
</p>
</div>
</div>
<div id="posix编程标准" class="section level3" number="10.3.2">
<h3><span class="header-section-number">10.3.2</span> POSIX编程标准</h3>
<p>POSIX（Portable Operating System Interface）属于早期的共享存储编程模型。POSIXThreads（）即Pthreads）代表官方IEEE POSIX1003.1C_1995线程标准，是由IEEE标准委员会所建立的，主要包含线程管理、线程调度、同步等原语定义，体现为C语言的一套函数库。下面只简介其公共性质。</p>
<p>1．线程管理</p>
<p>线程库用于管理线程，Pthreads中基本线程管理原语如下表所示。其中pthread_create()在进程内生成新线程，新线程执行带有变元arg的myroutine,如果pthread_create()生成，则返回0并将新线程之ID置入thread_id，否则返回指明错误类型的错误代码；pthread_exit()结束调用线程并执行清场处理；pthread_self()返回调用线程的ID；pthread_join()等待其他线程结束。</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:thread"></span>
<img src="images/chapter10/%E7%BA%BF%E7%A8%8B%E7%AE%A1%E7%90%86-01.png" alt="线程管理" width="100%" />
<p class="caption">
图 10.5: 线程管理
</p>
</div>
<p>2．线程调度</p>
<p>pthread_yield()的功能是使调用者将处理器让位于其他线程；pthread_cancel()的功能是中止指定的线程。</p>
<p>3．线程同步</p>
<p>Pthreads中的同步原语见下表。重点讨论互斥变量mutex（Mutual Exclusion）和条件变量cond（Conditional）。前者类似于信号灯结构；后者类似于事件结构。注意，使用同步变量之前需被初始化（生成），用后应销毁。</p>
<p>如果mutex未被上锁，pthread_mutex_lock()将锁住mutex；如果mutex已被上锁，调用线程一直被阻塞到mutex变成有效。pthead_mutex_trylock()的功能是尝试对mutex上锁。pthread_mutex_lock()和pthead_mutex_trylock()的区别是：前者会阻塞等待另外一锁被解锁；后者尝试去加锁，如果不成功就返回非0，如果成功返回0，不会产生阻塞。pthead_mutex_unlock()解锁先前上锁的mutex,当mutex被解锁，它就能由别的线程获取。</p>
<p>pthread_cond_wait()自动阻塞等待条件满足的现行线程，并开锁mutex。pthread_cond_timedwait()与pthread_cond_wait()类似，除了当等待时间达到时限它将解除阻塞外。pthread_cond_signal()解除一个等待条件满足的已被阻塞的线程的阻塞。pthread_cond_broadcast()将所有等待条件满足的已被阻塞的线程解除阻塞。</p>
<table>
<thead>
<tr class="header">
<th>功能</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>pthread_mutex_init(…)</td>
<td>生成新的互斥变量</td>
</tr>
<tr class="even">
<td>pthread_mutex_destroy(…)</td>
<td>销毁互斥变量</td>
</tr>
<tr class="odd">
<td>pthread_mutex_lock(…)</td>
<td>锁住互斥变量</td>
</tr>
<tr class="even">
<td>pthread_mutex_trylock(…)</td>
<td>尝试锁住互斥变量</td>
</tr>
<tr class="odd">
<td>pthread_mutex_unlock(…)</td>
<td>解锁互斥变量</td>
</tr>
<tr class="even">
<td>pthread_cond_init(…)</td>
<td>生成新的条件变量</td>
</tr>
<tr class="odd">
<td>pthread_cond_destroy(…)</td>
<td>销毁条件变量</td>
</tr>
<tr class="even">
<td>pthread_cond_wait(…)</td>
<td>等待（阻塞）条件变量</td>
</tr>
<tr class="odd">
<td>pthread_cond_timedwait(…)</td>
<td>等待条件变量直至到达时限</td>
</tr>
<tr class="even">
<td>pthread_cond_signal(…)</td>
<td>投递一个事件，解锁一个等待进程</td>
</tr>
<tr class="odd">
<td>pthread_cond_broadcast(…)</td>
<td>投递一个事件，解锁所有等待进程</td>
</tr>
</tbody>
</table>
<p>4.示例</p>
<p>以下程序示例用数值积分法求π的近似值。</p>
<p>我们使用梯形规则来求解这个积分。其基本思想是用一系列矩形填充一条曲线下的区域，就是要求出在区间[0,1]内函数曲线4/（1+x2）下的面积，此面积就是π的近似值。为此先将区间[0,1]划分成N个等间隔的子区间，每个子区间的宽度为1.0/N；然后计算出各子区间中点处的函数值；再将各子区间面积相加就可得出π的近似值。N的值越大，π值的误差越小。下代码块为进行π值计算的C语言描述的串行代码。为简化起见，将积分中的迭代次数固定为1 000 000。</p>
<p>利用梯形规则计算π的C语言串行代码</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb35-1"><a href="并行编程基础.html#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb35-2"><a href="并行编程基础.html#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;math.h&gt;</span></span>
<span id="cb35-3"><a href="并行编程基础.html#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main(){</span>
<span id="cb35-4"><a href="并行编程基础.html#cb35-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> i;</span>
<span id="cb35-5"><a href="并行编程基础.html#cb35-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> num_steps=<span class="dv">1000000</span>;</span>
<span id="cb35-6"><a href="并行编程基础.html#cb35-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">double</span> x,pi,step,sum=<span class="fl">0.0</span>;</span>
<span id="cb35-7"><a href="并行编程基础.html#cb35-7" aria-hidden="true" tabindex="-1"></a>    step = <span class="fl">1.0</span>/(<span class="dt">double</span>) num_steps;</span>
<span id="cb35-8"><a href="并行编程基础.html#cb35-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i=<span class="dv">0</span>;i&lt;num_steps;i++){  </span>
<span id="cb35-9"><a href="并行编程基础.html#cb35-9" aria-hidden="true" tabindex="-1"></a>        x=(i+<span class="fl">0.5</span>)*step;</span>
<span id="cb35-10"><a href="并行编程基础.html#cb35-10" aria-hidden="true" tabindex="-1"></a>        sum = sum+<span class="fl">4.0</span>/(<span class="fl">1.0</span>+x*x);</span>
<span id="cb35-11"><a href="并行编程基础.html#cb35-11" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb35-12"><a href="并行编程基础.html#cb35-12" aria-hidden="true" tabindex="-1"></a>    pi = step*sum;</span>
<span id="cb35-13"><a href="并行编程基础.html#cb35-13" aria-hidden="true" tabindex="-1"></a>    printf(<span class="st">&quot;pi %1f</span><span class="sc">\n</span><span class="st">&quot;</span>, pi);</span>
<span id="cb35-14"><a href="并行编程基础.html#cb35-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span>
<span id="cb35-15"><a href="并行编程基础.html#cb35-15" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>为采用Pthreads的并行化代码。</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb36-1"><a href="并行编程基础.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span></span>
<span id="cb36-2"><a href="并行编程基础.html#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb36-3"><a href="并行编程基础.html#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;pthread.h&gt;</span></span>
<span id="cb36-4"><a href="并行编程基础.html#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="pp">#define NUM_THREADS 4 </span><span class="co">//假设线程数目为4</span></span>
<span id="cb36-5"><a href="并行编程基础.html#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> num_steps = <span class="dv">1000000</span>;</span>
<span id="cb36-6"><a href="并行编程基础.html#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="dt">double</span> step = <span class="fl">0.0</span>, sum = <span class="fl">0.0</span>;</span>
<span id="cb36-7"><a href="并行编程基础.html#cb36-7" aria-hidden="true" tabindex="-1"></a>pthread_mutex_t mutex;</span>
<span id="cb36-8"><a href="并行编程基础.html#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> *countPI(<span class="dt">void</span> *id) {</span>
<span id="cb36-9"><a href="并行编程基础.html#cb36-9" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> index = (<span class="dt">int</span> ) id;</span>
<span id="cb36-10"><a href="并行编程基础.html#cb36-10" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> start = index*(num_steps/NUM_THREADS);</span>
<span id="cb36-11"><a href="并行编程基础.html#cb36-11" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> end;</span>
<span id="cb36-12"><a href="并行编程基础.html#cb36-12" aria-hidden="true" tabindex="-1"></a>    <span class="dt">double</span> x = <span class="fl">0.0</span>, y = <span class="fl">0.0</span>;</span>
<span id="cb36-13"><a href="并行编程基础.html#cb36-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (index == NUM_THREADS-<span class="dv">1</span>)</span>
<span id="cb36-14"><a href="并行编程基础.html#cb36-14" aria-hidden="true" tabindex="-1"></a>        end = num_steps;</span>
<span id="cb36-15"><a href="并行编程基础.html#cb36-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span></span>
<span id="cb36-16"><a href="并行编程基础.html#cb36-16" aria-hidden="true" tabindex="-1"></a>        end = start+(num_steps/NUM_THREADS);</span>
<span id="cb36-17"><a href="并行编程基础.html#cb36-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-18"><a href="并行编程基础.html#cb36-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (<span class="dt">int</span> i=start; i&lt;end; i++){</span>
<span id="cb36-19"><a href="并行编程基础.html#cb36-19" aria-hidden="true" tabindex="-1"></a>        x=(i+<span class="fl">0.5</span>)*step;</span>
<span id="cb36-20"><a href="并行编程基础.html#cb36-20" aria-hidden="true" tabindex="-1"></a>        y +=<span class="fl">4.0</span>/(<span class="fl">1.0</span>+x*x);</span>
<span id="cb36-21"><a href="并行编程基础.html#cb36-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb36-22"><a href="并行编程基础.html#cb36-22" aria-hidden="true" tabindex="-1"></a>    pthread_mutex_lock(&amp;mutex);</span>
<span id="cb36-23"><a href="并行编程基础.html#cb36-23" aria-hidden="true" tabindex="-1"></a>    sum += y;</span>
<span id="cb36-24"><a href="并行编程基础.html#cb36-24" aria-hidden="true" tabindex="-1"></a>    pthread_mutex_unlock(&amp;mutex);</span>
<span id="cb36-25"><a href="并行编程基础.html#cb36-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb36-26"><a href="并行编程基础.html#cb36-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-27"><a href="并行编程基础.html#cb36-27" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main() {</span>
<span id="cb36-28"><a href="并行编程基础.html#cb36-28" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> i;</span>
<span id="cb36-29"><a href="并行编程基础.html#cb36-29" aria-hidden="true" tabindex="-1"></a>    <span class="dt">double</span> pi;</span>
<span id="cb36-30"><a href="并行编程基础.html#cb36-30" aria-hidden="true" tabindex="-1"></a>    step = <span class="fl">1.0</span> / num_steps;</span>
<span id="cb36-31"><a href="并行编程基础.html#cb36-31" aria-hidden="true" tabindex="-1"></a>    sum = <span class="fl">0.0</span>;</span>
<span id="cb36-32"><a href="并行编程基础.html#cb36-32" aria-hidden="true" tabindex="-1"></a>    pthread_t tids[NUM_THREADS];</span>
<span id="cb36-33"><a href="并行编程基础.html#cb36-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-34"><a href="并行编程基础.html#cb36-34" aria-hidden="true" tabindex="-1"></a>    pthread_mutex_init(&amp;mutex, NULL);</span>
<span id="cb36-35"><a href="并行编程基础.html#cb36-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i=<span class="dv">0</span>; i&lt;NUM_THREADS; i++) {</span>
<span id="cb36-36"><a href="并行编程基础.html#cb36-36" aria-hidden="true" tabindex="-1"></a>        pthread_create(&amp;tids[i], NULL, countPI, (<span class="dt">void</span> *) i);</span>
<span id="cb36-37"><a href="并行编程基础.html#cb36-37" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb36-38"><a href="并行编程基础.html#cb36-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i=<span class="dv">0</span>; i&lt;NUM_THREADS; i++)</span>
<span id="cb36-39"><a href="并行编程基础.html#cb36-39" aria-hidden="true" tabindex="-1"></a>        pthread_join(tids[i], NULL);</span>
<span id="cb36-40"><a href="并行编程基础.html#cb36-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-41"><a href="并行编程基础.html#cb36-41" aria-hidden="true" tabindex="-1"></a>    pthread_mutex_destroy(&amp;mutex);</span>
<span id="cb36-42"><a href="并行编程基础.html#cb36-42" aria-hidden="true" tabindex="-1"></a>    pi = step*sum;</span>
<span id="cb36-43"><a href="并行编程基础.html#cb36-43" aria-hidden="true" tabindex="-1"></a>    printf(<span class="st">&quot;pi %1f</span><span class="sc">\n</span><span class="st">&quot;</span>, pi);</span>
<span id="cb36-44"><a href="并行编程基础.html#cb36-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span>
<span id="cb36-45"><a href="并行编程基础.html#cb36-45" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>下面举一个矩阵乘的Pthreads并行代码例子。该例子将两个n阶的方阵A和B相乘，结果存放在方阵C中。</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb37-1"><a href="并行编程基础.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span></span>
<span id="cb37-2"><a href="并行编程基础.html#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb37-3"><a href="并行编程基础.html#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;pthread.h&gt;</span></span>
<span id="cb37-4"><a href="并行编程基础.html#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="pp">#define NUM_THREADS 4 </span><span class="co">//假设线程数目为4</span></span>
<span id="cb37-5"><a href="并行编程基础.html#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="pp">#define n 1000</span></span>
<span id="cb37-6"><a href="并行编程基础.html#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="dt">double</span> *A,*B,*C;</span>
<span id="cb37-7"><a href="并行编程基础.html#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> *matrixMult(<span class="dt">void</span> *id) {<span class="co">//计算矩阵乘</span></span>
<span id="cb37-8"><a href="并行编程基础.html#cb37-8" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> my_id = (<span class="dt">int</span>)id;</span>
<span id="cb37-9"><a href="并行编程基础.html#cb37-9" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> i,j,k,start,end;</span>
<span id="cb37-10"><a href="并行编程基础.html#cb37-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">//计算进程负责的部分</span></span>
<span id="cb37-11"><a href="并行编程基础.html#cb37-11" aria-hidden="true" tabindex="-1"></a>    start = my_id*(n/NUM_THREADS);</span>
<span id="cb37-12"><a href="并行编程基础.html#cb37-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(my_id == NUM_THREADS-<span class="dv">1</span>)</span>
<span id="cb37-13"><a href="并行编程基础.html#cb37-13" aria-hidden="true" tabindex="-1"></a>    end = n;</span>
<span id="cb37-14"><a href="并行编程基础.html#cb37-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span></span>
<span id="cb37-15"><a href="并行编程基础.html#cb37-15" aria-hidden="true" tabindex="-1"></a>    end = start+(n/NUM_THREADS);</span>
<span id="cb37-16"><a href="并行编程基础.html#cb37-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i=start;i&lt;end;i++)</span>
<span id="cb37-17"><a href="并行编程基础.html#cb37-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(j=<span class="dv">0</span>;j&lt;n;j++) {</span>
<span id="cb37-18"><a href="并行编程基础.html#cb37-18" aria-hidden="true" tabindex="-1"></a>        C[i*n+j] = <span class="dv">0</span>;</span>
<span id="cb37-19"><a href="并行编程基础.html#cb37-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span>(k=<span class="dv">0</span>;k&lt;n;k++)</span>
<span id="cb37-20"><a href="并行编程基础.html#cb37-20" aria-hidden="true" tabindex="-1"></a>            C[i*n+j]+=A[i*n+k]*B[k*n+j];</span>
<span id="cb37-21"><a href="并行编程基础.html#cb37-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb37-22"><a href="并行编程基础.html#cb37-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-23"><a href="并行编程基础.html#cb37-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-24"><a href="并行编程基础.html#cb37-24" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main() {</span>
<span id="cb37-25"><a href="并行编程基础.html#cb37-25" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> i,j;</span>
<span id="cb37-26"><a href="并行编程基础.html#cb37-26" aria-hidden="true" tabindex="-1"></a>    pthread_t tids[NUM_THREADS];</span>
<span id="cb37-27"><a href="并行编程基础.html#cb37-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">//分配数据空间</span></span>
<span id="cb37-28"><a href="并行编程基础.html#cb37-28" aria-hidden="true" tabindex="-1"></a>    A = (<span class="dt">double</span> *)malloc(<span class="kw">sizeof</span>(<span class="dt">double</span>)*n*n);</span>
<span id="cb37-29"><a href="并行编程基础.html#cb37-29" aria-hidden="true" tabindex="-1"></a>    B = (<span class="dt">double</span> *)malloc(<span class="kw">sizeof</span>(<span class="dt">double</span>)*n*n);</span>
<span id="cb37-30"><a href="并行编程基础.html#cb37-30" aria-hidden="true" tabindex="-1"></a>    C = (<span class="dt">double</span> *)malloc(<span class="kw">sizeof</span>(<span class="dt">double</span>)*n*n);</span>
<span id="cb37-31"><a href="并行编程基础.html#cb37-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">//初始化数组</span></span>
<span id="cb37-32"><a href="并行编程基础.html#cb37-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i=<span class="dv">0</span>;i&lt;n;i++)</span>
<span id="cb37-33"><a href="并行编程基础.html#cb37-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(j=<span class="dv">0</span>;j&lt;n;j++){ </span>
<span id="cb37-34"><a href="并行编程基础.html#cb37-34" aria-hidden="true" tabindex="-1"></a>        A[i*n+j] = <span class="fl">1.0</span>;</span>
<span id="cb37-35"><a href="并行编程基础.html#cb37-35" aria-hidden="true" tabindex="-1"></a>        B[i*n+j] = <span class="fl">1.0</span>;</span>
<span id="cb37-36"><a href="并行编程基础.html#cb37-36" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb37-37"><a href="并行编程基础.html#cb37-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-38"><a href="并行编程基础.html#cb37-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i=<span class="dv">0</span>; i&lt;NUM_THREADS; i++)</span>
<span id="cb37-39"><a href="并行编程基础.html#cb37-39" aria-hidden="true" tabindex="-1"></a>        pthread_create(&amp;tids[i], NULL, matrixMult, (<span class="dt">void</span> *) i);</span>
<span id="cb37-40"><a href="并行编程基础.html#cb37-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i=<span class="dv">0</span>; i&lt;NUM_THREADS; i++)</span>
<span id="cb37-41"><a href="并行编程基础.html#cb37-41" aria-hidden="true" tabindex="-1"></a>        pthread_join(tids[i], NULL);</span>
<span id="cb37-42"><a href="并行编程基础.html#cb37-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span>
<span id="cb37-43"><a href="并行编程基础.html#cb37-43" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div>
<div id="openmp标准" class="section level3" number="10.3.3">
<h3><span class="header-section-number">10.3.3</span> OpenMP标准</h3>
<p>OpenMP是由OpenMP Architecture Review Board（ARB，结构审议委员会）牵头提出的，是一种用于共享存储并行系统的编程标准。最初的OpenMP标准形成于1997年，2002年发布了OpenMP 2.0标准，2008年发布了OpenMP3.0标准，2013年发布了OpenMP 4.0标准。实际上，OpenMP不是一种新语言，是对基本编程语言进行编译制导（Compiler Directive）扩展，支持C/C++和Fortran。由于OpenMP制导嵌入到C/C++、Fortran语言中，所以就具体语言不同会有所区别，本书介绍主要参考支持C/C++的OpenMP 4.0标准。</p>
<p>OpenMP标准中定义了制导指令、运行库和环境变量，使得用户可以按照标准逐步将已有串行程序并行化。制导语句是对程序设计语言的扩展，提供了对并行区域、工作共享、同步构造的支持；运行库和环境变量使用户可以调整并行程序的执行环境。程序员通过在程序源代码中加入专用pragma制导语句（以“#pragmaomp”字符串开头）来指明自己的意图，支持OpenMP标准的编译器可以自动将程序进行并行化，并在必要之处加入同步互斥以及通信。当选择忽略这些pragma，或者编译器不支持OpenMP时，程序又可退化为普通程序(一般为串行)，代码仍然可以正常运行，只是不能利用多线程来加速程序执行。</p>
<p>由于OpenMP标准具有简单、移植性好和可扩展等优点，目前已被广泛接受，主流处理器平台均支持OpenMP编译器，如Intel、AMD、IBM、龙芯等。开源编译器GCC也支持OpenMP标准。</p>
<p>1.OpenMP的并行执行模型</p>
<p>OpenMP是一个基于线程的并行编程模型，一个OpenMP进程由多个线程组成，使用fork-join并行执行模型。OpenMP程序开始于一个单独的主线程（Master Thread），主线程串行执行，遇到一个并行域（Parallel Region）开始并行执行。接下来的过程如下：</p>
<p>1）fork（分叉）。主线程派生出一队并行的线程，并行域的代码在主线程和派生出的线程间并行执行。</p>
<p>2）join（合并）。当派生线程在并行域中执行完后，它们或被阻塞或被中断，所计算的结果会被主线程收集，最后只有主线程在执行。</p>
<p>实际上，OpenMP的并行化都是使用嵌入到C/C++或者Fortran语言的制导语句来实现的。以下代码为OpenMP程序的并行结构。</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb38-1"><a href="并行编程基础.html#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;omp.h&gt;</span></span>
<span id="cb38-2"><a href="并行编程基础.html#cb38-2" aria-hidden="true" tabindex="-1"></a>main(){</span>
<span id="cb38-3"><a href="并行编程基础.html#cb38-3" aria-hidden="true" tabindex="-1"></a>   <span class="dt">int</span> var1,var2,var3;</span>
<span id="cb38-4"><a href="并行编程基础.html#cb38-4" aria-hidden="true" tabindex="-1"></a>   …</span>
<span id="cb38-5"><a href="并行编程基础.html#cb38-5" aria-hidden="true" tabindex="-1"></a>   <span class="pp">#pragma omp parallel private(var1,var2)  shared(var3)</span></span>
<span id="cb38-6"><a href="并行编程基础.html#cb38-6" aria-hidden="true" tabindex="-1"></a>   {</span>
<span id="cb38-7"><a href="并行编程基础.html#cb38-7" aria-hidden="true" tabindex="-1"></a>      …</span>
<span id="cb38-8"><a href="并行编程基础.html#cb38-8" aria-hidden="true" tabindex="-1"></a>   } </span>
<span id="cb38-9"><a href="并行编程基础.html#cb38-9" aria-hidden="true" tabindex="-1"></a>   …</span>
<span id="cb38-10"><a href="并行编程基础.html#cb38-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>2.编译制导语句</p>
下面介绍编译制导语句的格式。参看前面的OpenMP程序并行结构的例子，在并行开始部分需要语句“#pragma omp parallel private(var1,var2) shared(var3)”。下表是编译制导语句的格式及解释。
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Compiler-guidance-language"></span>
<img src="images/chapter10/%E7%BC%96%E8%AF%91%E5%88%B6%E5%AF%BC%E8%AF%AD%E8%A8%80-01.png" alt="编译制导语言" width="100%" />
<p class="caption">
图 10.6: 编译制导语言
</p>
</div>
<p>3.并行域结构</p>
<p>一个并行域就是一个能被多个线程执行的程序块，它是最基本的OpenMP并行结构。并行域的具体格式为：</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb39-1"><a href="并行编程基础.html#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp parallel [if(scalar_expression)| num_threads(integer-</span></span>
<span id="cb39-2"><a href="并行编程基础.html#cb39-2" aria-hidden="true" tabindex="-1"></a>expression）|<span class="cf">default</span>(shared|none)|<span class="kw">private</span>(list)|firstprivate(list)|shared</span>
<span id="cb39-3"><a href="并行编程基础.html#cb39-3" aria-hidden="true" tabindex="-1"></a>(list)| copyin(list)|reduction(<span class="kw">operator</span>:list)| </span>
<span id="cb39-4"><a href="并行编程基础.html#cb39-4" aria-hidden="true" tabindex="-1"></a>proc_bind(master|close|spread)] </span>
<span id="cb39-5"><a href="并行编程基础.html#cb39-5" aria-hidden="true" tabindex="-1"></a>newline</span></code></pre></div>
<p>当一个线程执行到parallel这个指令时，线程就会生成一列线程，线程号依次从0到n-1，而它自己会成为主线程（线程号为0）。当并行域开始时，程序代码就会被复制，每个线程都会执行该代码。这就意味着，到了并行域结束就会有一个栅障,且只有主线程能够通过这个栅障。</p>
<p>4.共享任务结构</p>
<p>共享任务结构将其内封闭的代码段划分给线程队列中的各线程执行。它不产生新的线程，在进入共享任务结构时不存在栅障，但是在共享任务结构结束时存在一个隐含的栅障。图<a href="并行编程基础.html#fig:shared-task">10.7</a>显示了3种典型的共享任务结构。其中：do/for将循环分布到线程列中执行，可看作是一种表达数据并行s的类型； sections把任务分割成多个各个部分（section），每个线程执行一个section，可很好地表达任务并行；single由线程队列中的一个线程串行执行。</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:shared-task"></span>
<img src="images/chapter10/shared_task.png" alt="共享任务类型" width="100%" />
<p class="caption">
图 10.7: 共享任务类型
</p>
</div>
<p>下面具体来看一下。</p>
<p>1）for编译制导语句。for语句（即C/C++中的for语句），表明若并行域已经初始化了，后面的循环就在线程队列中并行执行，否则就会顺序执行。语句格式如下：</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb40-1"><a href="并行编程基础.html#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp for [private(list)|firstprivate(list)|lastprivate(list)|</span></span>
<span id="cb40-2"><a href="并行编程基础.html#cb40-2" aria-hidden="true" tabindex="-1"></a>reduction(reduction-identifier:list)|schedule(kind[,chunk_size])|colla</span>
<span id="cb40-3"><a href="并行编程基础.html#cb40-3" aria-hidden="true" tabindex="-1"></a>pse(n)|ordered| nowait] </span>
<span id="cb40-4"><a href="并行编程基础.html#cb40-4" aria-hidden="true" tabindex="-1"></a>newline</span></code></pre></div>
<p>其中，schedule子句描述如何在线程队列中划分循环。kind为static时，将循环划分为chunk_size大小的循环块，静态分配给线程执行，若chunk_size没有声明，则尽量将循环在线程队列中平分；kind为dynamic时，线程会动态请求循环块来执行，执行完一个循环块后就申请下一个循环块，直到所有循环都执行完，循环块的大小为chunk_size，若chunk_size没有声明，则默认的块长度为1；kind为guide时，线程会动态请求循环块来执行，循环块的大小为未调度的循环数除以线程数，但循环块大小不能小于chunk_size（除了最后一块），若chunk_size没有声明，则默认为1。</p>
<p>2）sections编译制导语句。该语句是非循环的共享任务结构，它表明内部的代码是被线程队列分割的。语句格式如下：</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb41-1"><a href="并行编程基础.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp sections [private(list)|firstprivate(list)|lastprivate(list)|</span></span>
<span id="cb41-2"><a href="并行编程基础.html#cb41-2" aria-hidden="true" tabindex="-1"></a>reduction(reduction-identifier:list)|nowait] </span>
<span id="cb41-3"><a href="并行编程基础.html#cb41-3" aria-hidden="true" tabindex="-1"></a>newline</span>
<span id="cb41-4"><a href="并行编程基础.html#cb41-4" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb41-5"><a href="并行编程基础.html#cb41-5" aria-hidden="true" tabindex="-1"></a>    [#pragma omp section newline]</span>
<span id="cb41-6"><a href="并行编程基础.html#cb41-6" aria-hidden="true" tabindex="-1"></a>       Structured_block</span>
<span id="cb41-7"><a href="并行编程基础.html#cb41-7" aria-hidden="true" tabindex="-1"></a>    [#pragma omp section newline</span>
<span id="cb41-8"><a href="并行编程基础.html#cb41-8" aria-hidden="true" tabindex="-1"></a>       Structured_block]</span>
<span id="cb41-9"><a href="并行编程基础.html#cb41-9" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>值得注意的是，在没有nowait子句时，sections后面有栅障。</p>
<p>3）single编译制导语句。该语句表明内部的代码只由一个线程执行。语句格式如下：</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb42-1"><a href="并行编程基础.html#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp single [private(list)|firstprivate(list)| </span></span>
<span id="cb42-2"><a href="并行编程基础.html#cb42-2" aria-hidden="true" tabindex="-1"></a>copyprivate(list)|nowait] newline</span>
<span id="cb42-3"><a href="并行编程基础.html#cb42-3" aria-hidden="true" tabindex="-1"></a>Structured_block</span></code></pre></div>
<p>若没有nowait子句，线程列中没有执行single语句的线程，会一直等到代码栅障同步才会继续往下执行。</p>
<p>5.组合的并行共享任务结构</p>
<p>下面介绍两种将并行域制导和共享任务制导组合在一起的编译制导语句。</p>
<p>1）parallel for编译制导语句。该语句表明一个并行域包含一个单独的for语句。语句格式如下：</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb43-1"><a href="并行编程基础.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp parallel for [if(scalar_expression)|num_threads(integer-</span></span>
<span id="cb43-2"><a href="并行编程基础.html#cb43-2" aria-hidden="true" tabindex="-1"></a>expression|<span class="cf">default</span>(shared|none)|private(list)|firstprivate(list)|lastpriv</span>
<span id="cb43-3"><a href="并行编程基础.html#cb43-3" aria-hidden="true" tabindex="-1"></a>ate(list)|shared(list)|copyin(list)|reduction(Structured_block:list)|proc</span>
<span id="cb43-4"><a href="并行编程基础.html#cb43-4" aria-hidden="true" tabindex="-1"></a>_bind(master|close|spread)|schedule(kind[,chunk_size])|collapse(n)|ordere</span>
<span id="cb43-5"><a href="并行编程基础.html#cb43-5" aria-hidden="true" tabindex="-1"></a>d]</span>
<span id="cb43-6"><a href="并行编程基础.html#cb43-6" aria-hidden="true" tabindex="-1"></a>newline</span>
<span id="cb43-7"><a href="并行编程基础.html#cb43-7" aria-hidden="true" tabindex="-1"></a>For_loop</span></code></pre></div>
<p>该语句的子句可以是parallel和for语句的任意子句组合，除了nowait子句。</p>
<p>2）parallel sections编译制导语句。该语句表明一个并行域包含单独的一个sections语句。语句格式如下：</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb44-1"><a href="并行编程基础.html#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp parallel sections [if(scalar_expression)|num_threads(integer-</span></span>
<span id="cb44-2"><a href="并行编程基础.html#cb44-2" aria-hidden="true" tabindex="-1"></a>expression)|<span class="cf">default</span>(shared|none)|private(list)|firstprivate(list)|lastpri</span>
<span id="cb44-3"><a href="并行编程基础.html#cb44-3" aria-hidden="true" tabindex="-1"></a>vate(list)|shared(list)|copyin(list)|reduction(Structured_block:list)|pro</span>
<span id="cb44-4"><a href="并行编程基础.html#cb44-4" aria-hidden="true" tabindex="-1"></a>c_bind(master|close|spread)]</span>
<span id="cb44-5"><a href="并行编程基础.html#cb44-5" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb44-6"><a href="并行编程基础.html#cb44-6" aria-hidden="true" tabindex="-1"></a>    [#progma omp section newline]</span>
<span id="cb44-7"><a href="并行编程基础.html#cb44-7" aria-hidden="true" tabindex="-1"></a>    Structured_block</span>
<span id="cb44-8"><a href="并行编程基础.html#cb44-8" aria-hidden="true" tabindex="-1"></a>    [#progma omp section newline</span>
<span id="cb44-9"><a href="并行编程基础.html#cb44-9" aria-hidden="true" tabindex="-1"></a>    Structured_block]</span>
<span id="cb44-10"><a href="并行编程基础.html#cb44-10" aria-hidden="true" tabindex="-1"></a>    …</span>
<span id="cb44-11"><a href="并行编程基础.html#cb44-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>同样，该语句的子句可以是parallel和for语句的任意子句组合，除了nowait子句。</p>
<p>6.同步结构</p>
<p>OpenMP提供了多种同步结构来控制与其他线程相关的线程的执行。下面列出几种常用的同步编译制导语句。</p>
<p>1）master编译制导语句。该语句表明一个只能被主线程执行的域。线程队列中所有其他线程必须跳过这部分代码的执行，语句中没有栅障。语句格式如下：</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb45-1"><a href="并行编程基础.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp master newline</span></span></code></pre></div>
<p>2）critical编译制导语句。该语句表明域中的代码一次只能由一个线程执行。语句格式如下：</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb46-1"><a href="并行编程基础.html#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp critical[name] newline</span></span></code></pre></div>
<p>3）barrier编译指导语句。该语句同步线程队列中的所有线程。当有一个barrier语句时，线程必须要等到所有的其他线程也到达这个栅障时才能继续执行。然后所有线程并行执行栅障之后的代码。语句格式如下：</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb47-1"><a href="并行编程基础.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp barrier newline</span></span></code></pre></div>
<p>4）atomic编译制导语句。该语句表明一个特别的存储单元只能原子地更新，而不允许让多个线程同时去写。语句格式如下：</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb48-1"><a href="并行编程基础.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp atomic newline</span></span></code></pre></div>
<p>另外，还有flush、order等语句。</p>
<p>7.数据环境</p>
<p>OpenMP中提供了用来控制并行域在多线程队列中执行时的数据环境的制导语句和子句。下面选择主要的进行简介。</p>
<p>1）threadprivate编译制导语句。该语句表明变量是复制的，每个线程都有自己私有的备份。这条语句必须出现在变量序列定义之后。每个线程都复制这个变量块，所以一个线程的写数据对其他线程是不可见的。语句格式如下：</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb49-1"><a href="并行编程基础.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp threadprivate(list)</span></span></code></pre></div>
<p>2）数据域属性子句。OpenMP的数据域属性子句用来定义变量的范围，它包括private、firstprivate、lastprivate、shared、default、reduction和copyin等。数据域变量与编译制导语句parallel、for、sections等配合使用，可控制变量的范围。它们在并行结构执行过程中控制数据环境。例如：哪些串行部分的数据变量被传到程序的并行部分以及如何传送；哪些变量对所有的并行部分是可见的；哪些变量是线程私有的；等等。具体说明如下。</p>
<ul>
<li>private子句：表示它列出的变量对于每个线程是局部的，即线程私有的。其格式为：</li>
</ul>
<div class="sourceCode" id="cb50"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb50-1"><a href="并行编程基础.html#cb50-1" aria-hidden="true" tabindex="-1"></a>private(list) </span></code></pre></div>
<ul>
<li>shared子句：表示它列出的变量被线程队列中的所有线程共享，程序员可以使多线程对其进行读写（例如通过critical语句）。其格式为：</li>
</ul>
<div class="sourceCode" id="cb51"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb51-1"><a href="并行编程基础.html#cb51-1" aria-hidden="true" tabindex="-1"></a>shared（list）</span></code></pre></div>
<ul>
<li>default子句：该子句让用户可以规定在并行域的词法范围内所有变量的一个默认属性（如可以是private、shared、none）。其格式为：</li>
</ul>
<div class="sourceCode" id="cb52"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb52-1"><a href="并行编程基础.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="cf">default</span>(shared|none) </span></code></pre></div>
<ul>
<li>firstprivate子句：该子句包含private子句的操作，并将其列出的变量的值初始化为并行域外同名变量的值。其格式为：</li>
</ul>
<div class="sourceCode" id="cb53"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb53-1"><a href="并行编程基础.html#cb53-1" aria-hidden="true" tabindex="-1"></a>firstprivate(list)</span></code></pre></div>
<ul>
<li>lastprivate子句：该子句包含private子句的操作，并将值复制给并行域外的同名变量。其格式为：</li>
</ul>
<div class="sourceCode" id="cb54"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb54-1"><a href="并行编程基础.html#cb54-1" aria-hidden="true" tabindex="-1"></a>lastprivate(list)</span></code></pre></div>
<ul>
<li>copyin子句：该子句赋予线程中变量与主线程中threadprivate同名变量的值。其格式为：</li>
</ul>
<div class="sourceCode" id="cb55"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb55-1"><a href="并行编程基础.html#cb55-1" aria-hidden="true" tabindex="-1"></a>copyin(list)</span></code></pre></div>
<ul>
<li>reduction子句：该子句用来归约其列表中出现的变量。归约操作可以是加、减、乘、与(and)、或(or)、相等(eqv)、不相等(neqv)、最大（max）、最小（min）等。其格式为：</li>
</ul>
<div class="sourceCode" id="cb56"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb56-1"><a href="并行编程基础.html#cb56-1" aria-hidden="true" tabindex="-1"></a>reduction(reduction-identifier:list)</span></code></pre></div>
<p>利用梯形规则计算π的OpenMP并行化的C语言代码示例</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb57-1"><a href="并行编程基础.html#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb57-2"><a href="并行编程基础.html#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;omp.h&gt;</span></span>
<span id="cb57-3"><a href="并行编程基础.html#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main(){</span>
<span id="cb57-4"><a href="并行编程基础.html#cb57-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> i;</span>
<span id="cb57-5"><a href="并行编程基础.html#cb57-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> num_steps=<span class="dv">1000000</span>;</span>
<span id="cb57-6"><a href="并行编程基础.html#cb57-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">double</span> x,pi,step,sum=<span class="fl">0.0</span>;</span>
<span id="cb57-7"><a href="并行编程基础.html#cb57-7" aria-hidden="true" tabindex="-1"></a>    step = <span class="fl">1.0</span>/(<span class="dt">double</span>) num_steps;</span>
<span id="cb57-8"><a href="并行编程基础.html#cb57-8" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># pragma omp parallel for private(i, x), reduction(+:sum)</span></span>
<span id="cb57-9"><a href="并行编程基础.html#cb57-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i=<span class="dv">0</span>;i&lt;num_steps;i++)</span>
<span id="cb57-10"><a href="并行编程基础.html#cb57-10" aria-hidden="true" tabindex="-1"></a>    {  </span>
<span id="cb57-11"><a href="并行编程基础.html#cb57-11" aria-hidden="true" tabindex="-1"></a>        x=(i+<span class="fl">0.5</span>)*step;</span>
<span id="cb57-12"><a href="并行编程基础.html#cb57-12" aria-hidden="true" tabindex="-1"></a>        sum = sum+<span class="fl">4.0</span>/(<span class="fl">1.0</span>+x*x);</span>
<span id="cb57-13"><a href="并行编程基础.html#cb57-13" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb57-14"><a href="并行编程基础.html#cb57-14" aria-hidden="true" tabindex="-1"></a>    pi = step*sum;</span>
<span id="cb57-15"><a href="并行编程基础.html#cb57-15" aria-hidden="true" tabindex="-1"></a>    printf(<span class="st">&quot;pi %1f</span><span class="sc">\n</span><span class="st">&quot;</span>, pi);</span>
<span id="cb57-16"><a href="并行编程基础.html#cb57-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span>
<span id="cb57-17"><a href="并行编程基础.html#cb57-17" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>将两个n阶的方阵A和B相乘，结果存放在方阵C中，矩阵乘的OpenMP并行代码示例</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb58-1"><a href="并行编程基础.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb58-2"><a href="并行编程基础.html#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;omp.h&gt;</span></span>
<span id="cb58-3"><a href="并行编程基础.html#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#define n 1000</span></span>
<span id="cb58-4"><a href="并行编程基础.html#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="dt">double</span> A[n][n],B[n][n],C[n][n];</span>
<span id="cb58-5"><a href="并行编程基础.html#cb58-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-6"><a href="并行编程基础.html#cb58-6" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main()</span>
<span id="cb58-7"><a href="并行编程基础.html#cb58-7" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb58-8"><a href="并行编程基础.html#cb58-8" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> i,j,k;</span>
<span id="cb58-9"><a href="并行编程基础.html#cb58-9" aria-hidden="true" tabindex="-1"></a>   <span class="co">//初始化矩阵A和矩阵B</span></span>
<span id="cb58-10"><a href="并行编程基础.html#cb58-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i=<span class="dv">0</span>;i&lt;n;i++)</span>
<span id="cb58-11"><a href="并行编程基础.html#cb58-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(j=<span class="dv">0</span>;j&lt;n;j++) {</span>
<span id="cb58-12"><a href="并行编程基础.html#cb58-12" aria-hidden="true" tabindex="-1"></a>        A[i][j] = <span class="fl">1.0</span>;</span>
<span id="cb58-13"><a href="并行编程基础.html#cb58-13" aria-hidden="true" tabindex="-1"></a>        B[i][j] = <span class="fl">1.0</span>;</span>
<span id="cb58-14"><a href="并行编程基础.html#cb58-14" aria-hidden="true" tabindex="-1"></a>    }   </span>
<span id="cb58-15"><a href="并行编程基础.html#cb58-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">//并行计算矩阵C</span></span>
<span id="cb58-16"><a href="并行编程基础.html#cb58-16" aria-hidden="true" tabindex="-1"></a>    <span class="pp">#pragma omp parallel for shared(A,B,C) private(i,j,k)</span></span>
<span id="cb58-17"><a href="并行编程基础.html#cb58-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i=<span class="dv">0</span>;i&lt;n;i++)</span>
<span id="cb58-18"><a href="并行编程基础.html#cb58-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(j=<span class="dv">0</span>;j&lt;n;j++){</span>
<span id="cb58-19"><a href="并行编程基础.html#cb58-19" aria-hidden="true" tabindex="-1"></a>        C[i][j] = <span class="dv">0</span>;</span>
<span id="cb58-20"><a href="并行编程基础.html#cb58-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(k=<span class="dv">0</span>;k&lt;n;k++)</span>
<span id="cb58-21"><a href="并行编程基础.html#cb58-21" aria-hidden="true" tabindex="-1"></a>        C[i][j]+=A[i][k]*B[k][j];</span>
<span id="cb58-22"><a href="并行编程基础.html#cb58-22" aria-hidden="true" tabindex="-1"></a>     }</span>
<span id="cb58-23"><a href="并行编程基础.html#cb58-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span>
<span id="cb58-24"><a href="并行编程基础.html#cb58-24" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div>
<div id="消息传递编程接口" class="section level3" number="10.3.4">
<h3><span class="header-section-number">10.3.4</span> 消息传递编程接口</h3>
<p>MPI（Message Passing Interface）定义了一组消息传递函数库的编程接口标准。1994年发布了MPI第1版MPI-1,1997年发布了扩充版MPI-2，2012年发布了MPI-3标准。有多种支持MPI标准的函数库实现，开源实现有MPICH（由Argonne National Laboratory (ANL) 和Mississippi State University开发）、Open MPI 和LAM/MPI（由Ohio超算中心开发）等；商业实现来自于Intel、Microsoft、HP公司等。MPI编译器用于编译和链接MPI程序，支持C、C++、Fortran语言，如mpicc支持C语言、mpic++支持C++语言、mpif90支持Fortran90。MPI具有高可移植性和易用性，对运行的硬件要求简单，是目前国际上最流行的并行编程环境之一。</p>
<p>在MPI编程模型中，计算由一个或多个通过调用库函数进行消息收/发通信的进程所组成。在绝大部分MPI实现中，一组固定的进程在程序初始化时生成，在一个处理器核上通常只生成一个进程。这些进程可以执行相同或不同的程序（相应地称为单程序多数据（SPMD)或多程序多数据（MPMD)模式）。进程间的通信可以是点到点的或者集合（Collective）的。MPI只是为程序员提供了一个并行环境库，程序员用标准串行语言编写代码，并在其中调用MPI的库函数来实现消息通信，进行并行处理。</p>
<p>1.最基本的MPI</p>
<p>MPI是个复杂的系统，包括129个函数（根据1994年发布的MPI标准)。事实上，1997年修订的MPI-2标准中函数已超过200个，目前最常用的也有约30个，但只需要6个最基本的函数就能编写MPI程序求解许多问题，如下表所示。</p>
<table>
<thead>
<tr class="header">
<th>序号</th>
<th>函数名</th>
<th>用途</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>MPI_Init()</td>
<td>初始化MPI执行环境</td>
</tr>
<tr class="even">
<td>2</td>
<td>MPI_Finalize</td>
<td>结束MPI执行环境</td>
</tr>
<tr class="odd">
<td>3</td>
<td>MPI_COMM_SIZE</td>
<td>确定进程数</td>
</tr>
<tr class="even">
<td>4</td>
<td>MPI_COMM_RANK</td>
<td>确定自己的进程标识符</td>
</tr>
<tr class="odd">
<td>5</td>
<td>MPI_SEND</td>
<td>发送一条消息</td>
</tr>
<tr class="even">
<td>6</td>
<td>MPI_RECV</td>
<td>接收一条信息</td>
</tr>
</tbody>
</table>
<p>下面的代码显示了这6个基本函数的功能及参数情况。其中，标号IN表明函数使用但是不能修改参数；OUT表明函数不使用但是可以修改参数；INOUT表明函数既可以使用也可以修改参数。</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb59-1"><a href="并行编程基础.html#cb59-1" aria-hidden="true" tabindex="-1"></a>MPI_INIT(<span class="dt">int</span> *argc, <span class="dt">char</span> *** argv)</span>
<span id="cb59-2"><a href="并行编程基础.html#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="co">//初始化计算,其中argc,argv只在C语言程序中需要，它们是main函数的参数</span></span>
<span id="cb59-3"><a href="并行编程基础.html#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co">// MPI_FINALIZE()</span></span>
<span id="cb59-4"><a href="并行编程基础.html#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co">//结束计算</span></span>
<span id="cb59-5"><a href="并行编程基础.html#cb59-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-6"><a href="并行编程基础.html#cb59-6" aria-hidden="true" tabindex="-1"></a>MPI_COMM_SIZE(comm,size)</span>
<span id="cb59-7"><a href="并行编程基础.html#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="co">//确定通信域的进程数</span></span>
<span id="cb59-8"><a href="并行编程基础.html#cb59-8" aria-hidden="true" tabindex="-1"></a>IN   comm     communicator(handle)</span>
<span id="cb59-9"><a href="并行编程基础.html#cb59-9" aria-hidden="true" tabindex="-1"></a>OUT  size     number of processes in the group of comm(integer)</span>
<span id="cb59-10"><a href="并行编程基础.html#cb59-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-11"><a href="并行编程基础.html#cb59-11" aria-hidden="true" tabindex="-1"></a>MPI_COMM_RANK(comm,pid)</span>
<span id="cb59-12"><a href="并行编程基础.html#cb59-12" aria-hidden="true" tabindex="-1"></a><span class="co">//确定当前进程在通信域中的进程号</span></span>
<span id="cb59-13"><a href="并行编程基础.html#cb59-13" aria-hidden="true" tabindex="-1"></a>IN   comm     communicator(handle)</span>
<span id="cb59-14"><a href="并行编程基础.html#cb59-14" aria-hidden="true" tabindex="-1"></a>OUT  pidrank of the calling process in group of comm(integer)</span>
<span id="cb59-15"><a href="并行编程基础.html#cb59-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-16"><a href="并行编程基础.html#cb59-16" aria-hidden="true" tabindex="-1"></a>MPI_SEND（buf, count, datatype, dest, tag, comm）</span>
<span id="cb59-17"><a href="并行编程基础.html#cb59-17" aria-hidden="true" tabindex="-1"></a><span class="co">//发送消息</span></span>
<span id="cb59-18"><a href="并行编程基础.html#cb59-18" aria-hidden="true" tabindex="-1"></a>IN   buf      initial address of send buffer(choice)</span>
<span id="cb59-19"><a href="并行编程基础.html#cb59-19" aria-hidden="true" tabindex="-1"></a>IN   count    number of elements to send(integer≥<span class="dv">0</span>)</span>
<span id="cb59-20"><a href="并行编程基础.html#cb59-20" aria-hidden="true" tabindex="-1"></a>IN   datatype datatype of each send buffer elements(handle)</span>
<span id="cb59-21"><a href="并行编程基础.html#cb59-21" aria-hidden="true" tabindex="-1"></a>IN   dest     rank of destination (integer)</span>
<span id="cb59-22"><a href="并行编程基础.html#cb59-22" aria-hidden="true" tabindex="-1"></a>IN   tag      message tag(integer)</span>
<span id="cb59-23"><a href="并行编程基础.html#cb59-23" aria-hidden="true" tabindex="-1"></a>IN   comm     communicator(handle)</span>
<span id="cb59-24"><a href="并行编程基础.html#cb59-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-25"><a href="并行编程基础.html#cb59-25" aria-hidden="true" tabindex="-1"></a>MPI_RECV（buf, count, datatype, source, tag, comm, status）</span>
<span id="cb59-26"><a href="并行编程基础.html#cb59-26" aria-hidden="true" tabindex="-1"></a><span class="co">//接收消息</span></span>
<span id="cb59-27"><a href="并行编程基础.html#cb59-27" aria-hidden="true" tabindex="-1"></a>OUT  buf      initial address of receivebuffer(choice)</span>
<span id="cb59-28"><a href="并行编程基础.html#cb59-28" aria-hidden="true" tabindex="-1"></a>IN   count    number of elements in receivebuffer (integer≥<span class="dv">0</span>)</span>
<span id="cb59-29"><a href="并行编程基础.html#cb59-29" aria-hidden="true" tabindex="-1"></a>IN   datatype datatype of eachreceive buffer elements(handle)</span>
<span id="cb59-30"><a href="并行编程基础.html#cb59-30" aria-hidden="true" tabindex="-1"></a>IN   source   rank of source or MPI_ANY_SOURCE (integer)</span>
<span id="cb59-31"><a href="并行编程基础.html#cb59-31" aria-hidden="true" tabindex="-1"></a>IN   tag      message tag or MPI_ANY_TAG (integer)</span>
<span id="cb59-32"><a href="并行编程基础.html#cb59-32" aria-hidden="true" tabindex="-1"></a>IN   comm     communicator(handle)</span>
<span id="cb59-33"><a href="并行编程基础.html#cb59-33" aria-hidden="true" tabindex="-1"></a>OUT  status   status object (Status)</span></code></pre></div>
<p>以下代码是一个简单C语言的MPI程序的例子，其中MPI_COMM_WORLD是一个缺省的进程组，它指明所有的进程都参与计算。</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb60-1"><a href="并行编程基础.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&quot;mpi.h&quot;</span></span>
<span id="cb60-2"><a href="并行编程基础.html#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main(<span class="dt">int</span> argc,<span class="dt">char</span> *argv[])</span>
<span id="cb60-3"><a href="并行编程基础.html#cb60-3" aria-hidden="true" tabindex="-1"></a>{  <span class="dt">int</span> myid,count;</span>
<span id="cb60-4"><a href="并行编程基础.html#cb60-4" aria-hidden="true" tabindex="-1"></a>   MPI_Init(&amp;agrc,&amp;argv); <span class="co">/*启动计算*/</span></span>
<span id="cb60-5"><a href="并行编程基础.html#cb60-5" aria-hidden="true" tabindex="-1"></a>   MPI_Comm_size(MPI_COMM_WORLD,&amp;count); <span class="co">/*获得进程总数*/</span></span>
<span id="cb60-6"><a href="并行编程基础.html#cb60-6" aria-hidden="true" tabindex="-1"></a>   MPI_Comm_rank(MPI_COMM_WORLD, &amp;myid);<span class="co">/*获得自己进程号*/</span></span>
<span id="cb60-7"><a href="并行编程基础.html#cb60-7" aria-hidden="true" tabindex="-1"></a>   printf(<span class="st">&quot;I am %d of %d</span><span class="sc">\n</span><span class="st">)&quot;</span>, myid,count);  <span class="co">/*打印消息*/</span></span>
<span id="cb60-8"><a href="并行编程基础.html#cb60-8" aria-hidden="true" tabindex="-1"></a>   MPI_Finalize();<span class="co">/*结束计算*/</span></span>
<span id="cb60-9"><a href="并行编程基础.html#cb60-9" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>2.集体通信</p>
<p>并行程序中经常需要一些进程组间的集体通信(Collective Communication),包括：①栅障(MPI_BARRIER)，同步所有进程；②广播(MPI_BCAST)，从一个进程发送一条数据给所有进程；③收集（MPI_GATHER），从所有进程收集数据到一个进程；④散播（MPI_SCATTER），从一个进程散发多条数据给所有进程；⑤归约(MPI_REDUCE、MPI_ALLREDUCE)，包括求和、求积等。这些函数的功能及参数描述参见MPI3.0标准。不同于点对点通信，所有的进程都必须执行集体通信函数。集体通信函数不需要同步操作就能使所有进程同步，因此可能造成死锁。这意味着集体通信函数必须在所有进程上以相同的顺序执行。</p>
<p>3.通信域</p>
<p>通信域（Communicator）提供了MPI中独立的安全的消息传递。MPI通信域包含进程组（Process Group）和通信上下文（Context）。其中进程组是参加通信的一个有限并有序的进程集合，如果一共有N个进程参加通信，则进程的编号从0到N-1。通信上下文提供一个相对独立的通信区域，消息总是在其被发送的上下文内被接收，不同上下文的消息互不干涉。通信上下文可以将不同的通信区别开来。MPI提供了一个预定义的通信域MPI_COMM_WORLD，MPI初始化后就会产生，它包含了初始化时可得的全部进程，进程由它们在MPI_COMM_WORLD组中的进[程号所标识。</p>
<p>用户可以在原有通信域的基础上定义新的通信域。MPI提供的通信域函数概括：①MPI_COMMDUP，它生成一个新的通信域，具有相同的进程组和新的上下文，这可确保不同目的通信不会混淆；②MPI_COMMSPLIT，它生成一个新的通信域，但只是给定进程组的子集，这些进程可相互通信而不必担心与其他并发计算相冲突；③MPI_INTERCOMMCREATE，它构造一个进程组之间的通信域，该通信域链接两组内的进程；④MPI_COMMFREE，它用来释放上述三个函数所生成的通信域。</p>
<p>4.MPI点对点通信</p>
<p>点到点通信（Point-to-Point Communication）是MPI中较复杂的部分，其数据传送有阻塞（Blocking）和非阻塞(Non_blocking)两种机制。在阻塞方式中，它必须等到消息从本地送出之后才可以执行后续的语句，保证了缓冲区等资源可再用；对于非阻塞方式，它无须等到消息从本地送出就可执行后续的语句，从而允许通信和计算的重叠，但非阻塞调用的返回并不保证资源的可再用性。</p>
<p>阻塞和非阻塞有四种通信模式：①标准模式，包括阻塞发送MPI_SEND、阻塞接收MPI_RECV、非阻塞发送MPI_ISEND和非阻塞接收MPI_IRECV；②缓冲模式，包括阻塞缓冲发送MPI_BSEND和非阻塞缓冲发送MPI_IBSEND；③同步模式，包括阻塞同步发送MPI_SSEND非阻塞同步发送MPI_ISSEND；④就绪模式，包括阻塞就绪发送MPI_RSEND和非阻塞就绪发送MPI_IRSEND。在标准通信模式中，MPI根据当前的状况选取其他三种模式或用户定义的其他模式；缓冲模式在相匹配的接收未开始的情况下，将送出的消息放在缓冲区内，这样发送者可以很快地继续计算，然后由系统处理放在缓冲区中的消息，但这占用内存且多了一次内存拷贝；在同步模式中，只有相匹配的接收操作开始后，发送才能返回；在就绪模式下，只有相匹配的接收操作启动后，发送操作才能开始。</p>
<p>在点到点通信中，发送和接收语句必须是匹配的。为了区分不同进程或同一进程发送来的不同消息，在这些语句中采用了通信域Comm和标志位tag来实现成对语句的匹配。</p>
<p>上述函数中，关于MPI_SEND和MPI_RECV的功能和定义可以参考下代码块，其他函数的描述可参考MPI3.0标准。</p>
<p>以下代码是计算π的C语言MPI程序的例子。</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb61-1"><a href="并行编程基础.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb61-2"><a href="并行编程基础.html#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&quot;mpi.h&quot;</span></span>
<span id="cb61-3"><a href="并行编程基础.html#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main(<span class="dt">int</span> argc, <span class="dt">char</span> **argv){</span>
<span id="cb61-4"><a href="并行编程基础.html#cb61-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> num_steps=<span class="dv">1000000</span>;</span>
<span id="cb61-5"><a href="并行编程基础.html#cb61-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">double</span> x,pi,step,sum,sumallprocs;</span>
<span id="cb61-6"><a href="并行编程基础.html#cb61-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span>  i,start, end,temp;</span>
<span id="cb61-7"><a href="并行编程基础.html#cb61-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">//进程编号及组中的进程数量, 进程编号的范围为0到num_procs-1</span></span>
<span id="cb61-8"><a href="并行编程基础.html#cb61-8" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> ID,num_procs;</span>
<span id="cb61-9"><a href="并行编程基础.html#cb61-9" aria-hidden="true" tabindex="-1"></a>    MPI_Status status;</span>
<span id="cb61-10"><a href="并行编程基础.html#cb61-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">//初始化MPI环境</span></span>
<span id="cb61-11"><a href="并行编程基础.html#cb61-11" aria-hidden="true" tabindex="-1"></a>    MPI_Init(&amp;argc,&amp;argv);</span>
<span id="cb61-12"><a href="并行编程基础.html#cb61-12" aria-hidden="true" tabindex="-1"></a>    MPI_Comm_rank(MPI_COMM_WORLD,&amp;ID);</span>
<span id="cb61-13"><a href="并行编程基础.html#cb61-13" aria-hidden="true" tabindex="-1"></a>    MPI_Comm_size(MPI_COMM_WORLD,&amp;num_procs);</span>
<span id="cb61-14"><a href="并行编程基础.html#cb61-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">//任务划分并计算</span></span>
<span id="cb61-15"><a href="并行编程基础.html#cb61-15" aria-hidden="true" tabindex="-1"></a>    step = <span class="fl">1.0</span>/num_steps;</span>
<span id="cb61-16"><a href="并行编程基础.html#cb61-16" aria-hidden="true" tabindex="-1"></a>    start = ID *(num_steps/num_procs) ;</span>
<span id="cb61-17"><a href="并行编程基础.html#cb61-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (ID == num_procs-<span class="dv">1</span>)</span>
<span id="cb61-18"><a href="并行编程基础.html#cb61-18" aria-hidden="true" tabindex="-1"></a>        end = num_steps;</span>
<span id="cb61-19"><a href="并行编程基础.html#cb61-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span></span>
<span id="cb61-20"><a href="并行编程基础.html#cb61-20" aria-hidden="true" tabindex="-1"></a>        end = start + num_steps/num_procs;</span>
<span id="cb61-21"><a href="并行编程基础.html#cb61-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i=start; i&lt;end;i++) {</span>
<span id="cb61-22"><a href="并行编程基础.html#cb61-22" aria-hidden="true" tabindex="-1"></a>        x=(i+<span class="fl">0.5</span>)*step;</span>
<span id="cb61-23"><a href="并行编程基础.html#cb61-23" aria-hidden="true" tabindex="-1"></a>        sum += <span class="fl">4.0</span>/(<span class="fl">1.0</span>+x*x);</span>
<span id="cb61-24"><a href="并行编程基础.html#cb61-24" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb61-25"><a href="并行编程基础.html#cb61-25" aria-hidden="true" tabindex="-1"></a>    MPI_Barrier(MPI_COMM_WORLD);</span>
<span id="cb61-26"><a href="并行编程基础.html#cb61-26" aria-hidden="true" tabindex="-1"></a>    MPI_Reduce(&amp;sum,&amp;sumallprocs,<span class="dv">1</span>,MPI_DOUBLE,MPI_SUM,<span class="dv">0</span>, MPI_COMM_WORLD);</span>
<span id="cb61-27"><a href="并行编程基础.html#cb61-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(ID==<span class="dv">0</span>) {</span>
<span id="cb61-28"><a href="并行编程基础.html#cb61-28" aria-hidden="true" tabindex="-1"></a>        pi = sumallprocs*step;</span>
<span id="cb61-29"><a href="并行编程基础.html#cb61-29" aria-hidden="true" tabindex="-1"></a>        printf(<span class="st">&quot;pi %1f</span><span class="sc">\n</span><span class="st">&quot;</span>, pi);</span>
<span id="cb61-30"><a href="并行编程基础.html#cb61-30" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb61-31"><a href="并行编程基础.html#cb61-31" aria-hidden="true" tabindex="-1"></a>    MPI_Finalize();</span>
<span id="cb61-32"><a href="并行编程基础.html#cb61-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span>
<span id="cb61-33"><a href="并行编程基础.html#cb61-33" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>以下代码是进行矩阵乘的C语言MPI程序的例子。该例子将两个n阶的方阵A和B相乘，结果存放在方阵C中，A、B、C都在节点0上，采用主从进程的计算方法，主进程将数据发送给从进程，从进程将计算结果返回给主进程。</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb62-1"><a href="并行编程基础.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb62-2"><a href="并行编程基础.html#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&quot;mpi.h&quot;</span></span>
<span id="cb62-3"><a href="并行编程基础.html#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#define n 1000</span></span>
<span id="cb62-4"><a href="并行编程基础.html#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main(<span class="dt">int</span> argc, <span class="dt">char</span> **argv)</span>
<span id="cb62-5"><a href="并行编程基础.html#cb62-5" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb62-6"><a href="并行编程基础.html#cb62-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">double</span>*A,*B,*C;</span>
<span id="cb62-7"><a href="并行编程基础.html#cb62-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> i,j,k;</span>
<span id="cb62-8"><a href="并行编程基础.html#cb62-8" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> ID,num_procs,line;</span>
<span id="cb62-9"><a href="并行编程基础.html#cb62-9" aria-hidden="true" tabindex="-1"></a>    MPI_Status status;</span>
<span id="cb62-10"><a href="并行编程基础.html#cb62-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-11"><a href="并行编程基础.html#cb62-11" aria-hidden="true" tabindex="-1"></a>    MPI_Init(&amp;argc,&amp;argv); <span class="co">//Initialize the MPI environment</span></span>
<span id="cb62-12"><a href="并行编程基础.html#cb62-12" aria-hidden="true" tabindex="-1"></a>    MPI_Comm_rank(MPI_COMM_WORLD,&amp;ID);<span class="co">//获取当前进程号</span></span>
<span id="cb62-13"><a href="并行编程基础.html#cb62-13" aria-hidden="true" tabindex="-1"></a>    MPI_Comm_size(MPI_COMM_WORLD,&amp;num_procs);<span class="co">//获取进程数目</span></span>
<span id="cb62-14"><a href="并行编程基础.html#cb62-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-15"><a href="并行编程基础.html#cb62-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">//分配数据空间</span></span>
<span id="cb62-16"><a href="并行编程基础.html#cb62-16" aria-hidden="true" tabindex="-1"></a>    A = (<span class="dt">double</span> *)malloc(<span class="kw">sizeof</span>(<span class="dt">double</span>)*n*n);</span>
<span id="cb62-17"><a href="并行编程基础.html#cb62-17" aria-hidden="true" tabindex="-1"></a>    B = (<span class="dt">double</span> *)malloc(<span class="kw">sizeof</span>(<span class="dt">double</span>)*n*n);</span>
<span id="cb62-18"><a href="并行编程基础.html#cb62-18" aria-hidden="true" tabindex="-1"></a>    C = (<span class="dt">double</span> *)malloc(<span class="kw">sizeof</span>(<span class="dt">double</span>)*n*n);</span>
<span id="cb62-19"><a href="并行编程基础.html#cb62-19" aria-hidden="true" tabindex="-1"></a>    line = n/num_procs;<span class="co">//按进程数来划分数据</span></span>
<span id="cb62-20"><a href="并行编程基础.html#cb62-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-21"><a href="并行编程基础.html#cb62-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(ID==<span class="dv">0</span>) { <span class="co">//节点0，主进程</span></span>
<span id="cb62-22"><a href="并行编程基础.html#cb62-22" aria-hidden="true" tabindex="-1"></a>        <span class="co">//初始化数组</span></span>
<span id="cb62-23"><a href="并行编程基础.html#cb62-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span>(i=<span class="dv">0</span>;i&lt;n;i++)</span>
<span id="cb62-24"><a href="并行编程基础.html#cb62-24" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span>(j=<span class="dv">0</span>;j&lt;n;j++){ </span>
<span id="cb62-25"><a href="并行编程基础.html#cb62-25" aria-hidden="true" tabindex="-1"></a>                A[i*n+j] = <span class="fl">1.0</span>;</span>
<span id="cb62-26"><a href="并行编程基础.html#cb62-26" aria-hidden="true" tabindex="-1"></a>                B[i*n+j] = <span class="fl">1.0</span>;</span>
<span id="cb62-27"><a href="并行编程基础.html#cb62-27" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb62-28"><a href="并行编程基础.html#cb62-28" aria-hidden="true" tabindex="-1"></a>        <span class="co">//将矩阵A、B的相应数据发送给从进程</span></span>
<span id="cb62-29"><a href="并行编程基础.html#cb62-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span>(i=<span class="dv">1</span>;i&lt;num_procs;i++) {</span>
<span id="cb62-30"><a href="并行编程基础.html#cb62-30" aria-hidden="true" tabindex="-1"></a>            MPI_Send(B,n*n,MPI_DOUBLE,i,<span class="dv">0</span>,MPI_COMM_WORLD);</span>
<span id="cb62-31"><a href="并行编程基础.html#cb62-31" aria-hidden="true" tabindex="-1"></a>            MPI_Send(A+(i-<span class="dv">1</span>)*line*n,line*n,MPI_DOUBLE,i,<span class="dv">1</span>,MPI_COMM_WORLD);</span>
<span id="cb62-32"><a href="并行编程基础.html#cb62-32" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb62-33"><a href="并行编程基础.html#cb62-33" aria-hidden="true" tabindex="-1"></a>        <span class="co">//接收从进程计算结果</span></span>
<span id="cb62-34"><a href="并行编程基础.html#cb62-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span>(i=<span class="dv">1</span>;i&lt;num_procs;i++) </span>
<span id="cb62-35"><a href="并行编程基础.html#cb62-35" aria-hidden="true" tabindex="-1"></a>            MPI_Recv(C+(i-<span class="dv">1</span>)*line*n,line*n,MPI_DOUBLE,i,<span class="dv">2</span>,MPI_COMM_WORLD,&amp;status);</span>
<span id="cb62-36"><a href="并行编程基础.html#cb62-36" aria-hidden="true" tabindex="-1"></a>        <span class="co">//计算剩下的数据</span></span>
<span id="cb62-37"><a href="并行编程基础.html#cb62-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span>(i=(num_procs-<span class="dv">1</span>)*line;i&lt;n;i++) </span>
<span id="cb62-38"><a href="并行编程基础.html#cb62-38" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span>(j=<span class="dv">0</span>;j&lt;n;j++) {</span>
<span id="cb62-39"><a href="并行编程基础.html#cb62-39" aria-hidden="true" tabindex="-1"></a>                C[i*n+j]=<span class="dv">0</span>;</span>
<span id="cb62-40"><a href="并行编程基础.html#cb62-40" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span>(k=<span class="dv">0</span>;k&lt;n;k++)</span>
<span id="cb62-41"><a href="并行编程基础.html#cb62-41" aria-hidden="true" tabindex="-1"></a>                    C[i*n+j]+=A[i*n+k]*B[k*n+j];</span>
<span id="cb62-42"><a href="并行编程基础.html#cb62-42" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb62-43"><a href="并行编程基础.html#cb62-43" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb62-44"><a href="并行编程基础.html#cb62-44" aria-hidden="true" tabindex="-1"></a>        <span class="co">//其他进程接收数据，计算结果，发送给主进程</span></span>
<span id="cb62-45"><a href="并行编程基础.html#cb62-45" aria-hidden="true" tabindex="-1"></a>        MPI_Recv(B,n*n,MPI_DOUBLE,<span class="dv">0</span>,<span class="dv">0</span>,MPI_COMM_WORLD,&amp;status);</span>
<span id="cb62-46"><a href="并行编程基础.html#cb62-46" aria-hidden="true" tabindex="-1"></a>        MPI_Recv(A+(ID-<span class="dv">1</span>)*line*n,line*n,MPI_DOUBLE,<span class="dv">0</span>,<span class="dv">1</span>,MPI_COMM_WORLD,&amp;status);</span>
<span id="cb62-47"><a href="并行编程基础.html#cb62-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span>(i=(ID-<span class="dv">1</span>)*line;i&lt;ID*line;i++)</span>
<span id="cb62-48"><a href="并行编程基础.html#cb62-48" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span>(j=<span class="dv">0</span>;j&lt;n;j++) {</span>
<span id="cb62-49"><a href="并行编程基础.html#cb62-49" aria-hidden="true" tabindex="-1"></a>                C[i*n+j]=<span class="dv">0</span>;</span>
<span id="cb62-50"><a href="并行编程基础.html#cb62-50" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span>(k=<span class="dv">0</span>;k&lt;n;k++)</span>
<span id="cb62-51"><a href="并行编程基础.html#cb62-51" aria-hidden="true" tabindex="-1"></a>                    C[i*n+j]+=A[i*n+k]*B[k*n+j];</span>
<span id="cb62-52"><a href="并行编程基础.html#cb62-52" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb62-53"><a href="并行编程基础.html#cb62-53" aria-hidden="true" tabindex="-1"></a>        MPI_SEND(C+(num_procs-<span class="dv">1</span>)*line*n,line*n,MPI_DOUBLE,<span class="dv">0</span>,<span class="dv">2</span>,MPI_COMM_WORLD);</span>
<span id="cb62-54"><a href="并行编程基础.html#cb62-54" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb62-55"><a href="并行编程基础.html#cb62-55" aria-hidden="true" tabindex="-1"></a>    MPI_Finalize();</span>
<span id="cb62-56"><a href="并行编程基础.html#cb62-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span>
<span id="cb62-57"><a href="并行编程基础.html#cb62-57" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div>
</div>
<div id="习题-9" class="section level2" number="10.4">
<h2><span class="header-section-number">10.4</span> 习题</h2>
<ol style="list-style-type: decimal">
<li><p>请介绍MPI中阻塞发送MPI_SEND/阻塞接收MPI_RECV与非阻塞发送MPI_ISEND/非阻塞接收MPI_IRECV的区别。</p></li>
<li><p>请介绍什么是归约（Reduce）操作，MPI和OpenMP中分别采用何种函数或者子句来实现归约操作。</p></li>
<li><p>请介绍什么是栅障（Barrier）操作，MPI和OpenMP中分别采用何种函数或者命令来实现栅障。</p></li>
<li><p>下面的MPI程序片段是否正确？请说明理由。假定只有2个进程正在运行且mypid为每个进程的进程号。</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb63-1"><a href="并行编程基础.html#cb63-1" aria-hidden="true" tabindex="-1"></a>If(mypid==<span class="dv">0</span>) {</span>
<span id="cb63-2"><a href="并行编程基础.html#cb63-2" aria-hidden="true" tabindex="-1"></a>    MPI_Bcast(buf0,count,type,<span class="dv">0</span>,comm,ierr);</span>
<span id="cb63-3"><a href="并行编程基础.html#cb63-3" aria-hidden="true" tabindex="-1"></a>    MPI_Send(buf1,count,type,<span class="dv">1</span>,tag,comm,ierr);</span>
<span id="cb63-4"><a href="并行编程基础.html#cb63-4" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb63-5"><a href="并行编程基础.html#cb63-5" aria-hidden="true" tabindex="-1"></a>    MPI_Recv(buf1,count,type,<span class="dv">0</span>,tag,comm,ierr);</span>
<span id="cb63-6"><a href="并行编程基础.html#cb63-6" aria-hidden="true" tabindex="-1"></a>    MPI_Bcast(buf0,count,type,<span class="dv">0</span>,comm,ierr);</span>
<span id="cb63-7"><a href="并行编程基础.html#cb63-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div></li>
<li><p>矩阵乘是数值计算中的重要运算。假设有一个m×p的矩阵A，还有一个p×n的矩阵B。令C为矩阵A与B的乘积，即C=AB。表示矩阵在（i,j）位置处的值，则0≤i≤m-1, 0≤j≤n-1。请采用OpenMP，将矩阵C的计算并行化。假设矩阵在存储器中按行存放。</p></li>
<li><p>请采用MPI将上题中矩阵C的计算并行化，并比较OpenMP与MPI并行程序的特点。</p></li>
<li><p>分析一款GPU的存储层次。</p></li>
</ol>
<div style="page-break-after: always;"></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="指令流水线.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="多核处理结构.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown.pdf", "bookdown.docx"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
